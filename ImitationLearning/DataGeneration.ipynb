{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOjV8sPDASg0FgjQp9wqwys"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"yCv9MViqINaF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import networkx as nx\n","import random\n","import numpy\n","\n","\n","def mc_upper_bound(G):\n","\t\"\"\"\n","\tINPUT:\n","\t - \"G\" Networkx Undirected Graph\n","\tOUTPUT:\n","\t - \"chromatic_number\" integer upper bound on the maximum clique number\n","\t\"\"\"\n","\tansw = nx.algorithms.coloring.greedy_color(G)\n","\tchromatic_number = list(set(list(answ.values())))\n","\treturn len(chromatic_number)\n","\n","def mc_lower_bound(G):\n","\t\"\"\"\n","\tINPUT:\n","\t - \"G\" Networkx Undirected Graph\n","\tOUTPUT:\n","\t - \"lower bound\" list of variables which form a clique in G\n","\t\"\"\"\n","\treturn nx.maximal_independent_set(nx.complement(G))\n","\n","def edge_k_core(G, k):\n","\t\"\"\"\n","\tINPUT:\n","\t - \"G\" Networkx Undirected Graph\n","\t - \"k\" Integer that is at least one less than the global maximum clique number\n","\tOUTPUT:\n","\t - \"G\" Networkx Undirected Graph where edge k-core reduction has been applied\n","\t\"\"\"\n","\tfor a in list(G.edges()):\n","\t\tx = list(G.neighbors(a[0]))\n","\t\ty = list(G.neighbors(a[1]))\n","\t\tif len(list(set(x) & set(y))) <= (k-2):\n","\t\t\tG.remove_edge(a[0], a[1])\n","\treturn G\n","\n","def k_core_reduction(graph, k):\n","\t\"\"\"\n","\tINPUT:\n","\t - \"graph\" Networkx Undirected Graph\n","\t - \"k\" Integer that is at least one less than the global maximum clique number\n","\tOUTPUT:\n","\t - \"graph\" Networkx Undirected Graph where k-core reduction has been applied\n","\t\"\"\"\n","\tgraph = nx.k_core(graph, k)\n","\tref1 = len(list(graph.edges()))\n","\tgraph = edge_k_core(graph, k)\n","\tref2 = len(list(graph.edges()))\n","\twhile ref1 != ref2:\n","\t\tif len(graph) == 0:\n","\t\t\treturn graph\n","\t\tgraph = nx.k_core(graph, k)\n","\t\tref1 = len(list(graph.edges()))\n","\t\tgraph = edge_k_core(graph, k)\n","\t\tref2 = len(list(graph.edges()))\n","\treturn graph\n","\n","def is_clique(G):\n","\t\"\"\"\n","\tINPUT:\n","\t - \"G\" Networkx Undirected Graph\n","\tOUTPUT:\n","\t - \"True\" if G is a clique, and \"False\" if G is not a clique\n","\t\"\"\"\n","\tn = len(list(G.nodes()))\n","\tm = len(list(G.edges()))\n","\tif int(m) == int((n*(n-1))/float(2)):\n","\t\treturn True\n","\telse:\n","\t\treturn False\n","\n","def ch_partitioning(vertex, G):\n","\t\"\"\"\n","\tINPUT:\n","\t - \"vertex\" splitting vertex\n","\t - \"G\" Networkx Undirected Graph\n","\tOUTPUT:\n","\t - \"SSG\" Left subgraph after partitioning\n","\t - \"SG\" Right subgraph after partitioning\n","\t\"\"\"\n","\tn = list(G.neighbors(vertex))\n","\tGp = []\n","\tfor iter in list(G.edges()):\n","\t\tif iter[0] in n:\n","\t\t\tif iter[1] in n:\n","\t\t\t\tGp.append(iter)\n","\tG.remove_node(vertex)\n","\treturn nx.Graph(Gp), G\n","\n","def lowest_degree_vertex(graph):\n","\t\"\"\"\n","\tINPUT:\n","\t - \"graph\" Networkx Undirected Graph\n","\tOUTPUT:\n","\t - \"i\" node that has the lowest degree in the graph\n","\t\"\"\"\n","\tdegrees = [graph.degree(a) for a in list(graph.nodes())]\n","\tminimum = min(degrees)\n","\tfor i in list(graph.nodes()):\n","\t\tif graph.degree(i) == minimum:\n","\t\t\treturn i\n","\n","def remove_zero_degree_nodes(graph):\n","\t\"\"\"\n","\tINPUT:\n","\t - \"graph\" Networkx Undirected Graph\n","\tOUTPUT:\n","\t - \"graph\" Networkx Undirected Graph with no zero degree nodes\n","\t\"\"\"\n","\tnodes = list(graph.nodes())\n","\tfor n in nodes:\n","\t\tif graph.degree(n) == 0:\n","\t\t\tgraph.remove_node(n)\n","\treturn graph\n","\n","def DBK(graph, LIMIT):\n","  \"\"\"\n","  INPUT:\n","    - \"graph\" must be a Networkx Undirected Graph\n","    - \"LIMIT\" is an integer describing the largest size of graph which solver_func can solve; all subgraph sizes solved will be less than or equal to LIMIT\n","    - \"solver_function\" takes a Networkx Graph, and outputs a list of nodes which are hopefully the Maximum Clique elements; it can be an approximate or exact solver function\n","  OUTPUT:\n","    - \"k\" is a list of graph nodes which form a clique in the input graph. If the solver is exact, then k is the Maximum Clique\n","  NOTES:\n","    - The central idea of using bounds is that we maintain a global lower bound on the Maximum Clique. Then, for each sub problem we calculate a fast upper bound.\n","      If any sub problem has an upper bound which is less than or equal to the global lower bound, we can remove that sub problem from consideration in the remaining iterations of the algorithm.\n","    - This algorithm does not necessarily enumerate all cliques nor all Maximum Cliques. In particular, it is designed to return a single maximum clique assuming the solver is exact.\n","      However, the algorithm could be modified to include all maximum cliques found from solving each sub-problem.\n","    - There are many assert statements in this function. These all serve as \"sanity checks\"; if any of them are tripped, something went wrong or an input was incorrect\n","  \"\"\"\n","  assert type(graph) is nx.Graph\n","  assert type(LIMIT) is int\n","  assert len(graph) != 0\n","  print(\"=== Starting DBK Algorithm ===\")\n","  G = graph.copy()\n","  num_of_atoms = 0\n","  iteration = 0\n","  atom_sizes = []\n","  if len(graph) <= LIMIT:\n","    print(\"=== Input Graph Size is Smaller than LIMIT ===\")\n","    num_of_atoms +=1\n","    print(\"=== Finished DBK Algorithm ===\")\n","    return num_of_atoms, iteration, atom_sizes\n","  print(\"Preprocessing...\")\n","  graph = remove_zero_degree_nodes(graph)\n","  k = mc_lower_bound(graph)\n","  graph = k_core_reduction(graph, len(k))\n","  if len(graph) == 0:\n","    return num_of_atoms, iteration, atom_sizes\n","  if len(graph) <= LIMIT:\n","    print(\"=== After K-core Reduction the Graph Size is Smaller than LIMIT ===\")\n","    num_of_atoms += 1\n","    print(\"=== Finished DBK Algorithm ===\")\n","    return num_of_atoms, iteration, atom_sizes\n","  vertex_removal = {graph: []}\n","  subgraphs = [graph]\n","  while len(subgraphs) != 0:\n","    iteration += 1\n","    SG = subgraphs.pop()\n","    SG = remove_zero_degree_nodes(SG)\n","    #print(\"Current subgraph size:\", len(SG))\n","    assert len(SG) != 0\n","    vcount = vertex_removal[SG]\n","    del vertex_removal[SG]\n","    vertex = lowest_degree_vertex(SG)\n","    SSG, SG = ch_partitioning(vertex, SG)\n","    SG = remove_zero_degree_nodes(SG) # BIG\n","    SSG = remove_zero_degree_nodes(SSG) # SMALL\n","    SG = k_core_reduction(SG, len(k)-len(vcount)) # 0\n","    SSG = k_core_reduction(SSG, len(k)-len(vcount+[vertex])) # 1\n","    vertex_removal[SSG] = vcount+[vertex]\n","    vertex_removal[SG] = vcount\n","    #####################################################################################################\n","    if is_clique(G.subgraph(list(SSG.nodes()))) == True:\n","      assert is_clique(G.subgraph(list(SSG.nodes())+vertex_removal[SSG])) == True\n","      if len(SSG)+len(vertex_removal[SSG]) > len(k):\n","        k = list(SSG.nodes())+vertex_removal[SSG]\n","      del vertex_removal[SSG]\n","      SSG = nx.Graph()\n","    if is_clique(G.subgraph(list(SG.nodes()))) == True:\n","      assert is_clique(G.subgraph(list(SG.nodes())+vertex_removal[SG])) == True\n","      if len(SG)+len(vertex_removal[SG]) > len(k):\n","        k = list(SG.nodes())+vertex_removal[SG]\n","      del vertex_removal[SG]\n","      SG = nx.Graph()\n","    #####################################################################################################\n","    if len(SSG) != 0:\n","      SSG_lower = mc_lower_bound(SSG)+vertex_removal[SSG]\n","      assert is_clique(G.subgraph(SSG_lower)) == True\n","      #print(\"SSG lower\", len(SSG_lower))\n","      #print(\"lowerbound:\", len(k))\n","      if len(SSG_lower) > len(k):\n","        vcount = vertex_removal[SSG]\n","        del vertex_removal[SSG]\n","        k = SSG_lower\n","        SSG = k_core_reduction(SSG, len(k)-len(vcount))\n","        SSG = remove_zero_degree_nodes(SSG)\n","        vertex_removal[SSG] = vcount\n","      if len(SSG) != 0:\n","        SSG_upper = mc_upper_bound(SSG)+len(vertex_removal[SSG])\n","        if SSG_upper > len(k):\n","          if len(SSG) <= LIMIT:\n","            #print(\"=== Terminal Subgraph Found ===\")\n","            #print(\"Size:\", len(SSG))\n","            atom_sizes.append(len(SSG))\n","            num_of_atoms += 1\n","            del vertex_removal[SSG]\n","          else:\n","            subgraphs.append(SSG)\n","        else:\n","          del vertex_removal[SSG]\n","    if len(SSG) == 0:\n","      if SSG in list(vertex_removal.keys()):\n","        sub_solution_SSG = vertex_removal[SSG]\n","        del vertex_removal[SSG]\n","        assert is_clique(G.subgraph(sub_solution_SSG)) == True\n","        if len(sub_solution_SSG) > len(k):\n","          k = sub_solution_SSG\n","    #####################################################################################################\n","    if len(SG) != 0:\n","      SG_lower = mc_lower_bound(SG)+vertex_removal[SG]\n","      assert is_clique(G.subgraph(SG_lower)) == True\n","      #print(\"SG lower\", len(SG_lower))\n","      #print(\"lowerbound:\", len(k))\n","      if len(SG_lower) > len(k):\n","        vcount = vertex_removal[SG]\n","        del vertex_removal[SG]\n","        k = SG_lower\n","        SG = k_core_reduction(SG, len(k)-len(vcount))\n","        SG = remove_zero_degree_nodes(SG)\n","        vertex_removal[SG] = vcount\n","      if len(SG) != 0:\n","        SG_upper = mc_upper_bound(SG)+len(vertex_removal[SG])\n","        if SG_upper > len(k):\n","          if len(SG) <= LIMIT:\n","            #print(\"=== Terminal Subgraph Found ===\")\n","            #print(\"Size:\", len(SG))\n","            atom_sizes.append(len(SG))\n","            num_of_atoms += 1\n","            # sub_solution_SG = solver_function(SG)+vertex_removal[SG]\n","            del vertex_removal[SG]\n","          else:\n","            subgraphs.append(SG)\n","        else:\n","          del vertex_removal[SG]\n","    if len(SG) == 0:\n","      if SG in list(vertex_removal.keys()):\n","        sub_solution_SG = vertex_removal[SG]\n","        del vertex_removal[SG]\n","        assert is_clique(G.subgraph(sub_solution_SG)) == True\n","        if len(sub_solution_SG) > len(k):\n","          k = sub_solution_SG\n","  assert len(vertex_removal) == 0\n","  print(\"=== Finished DBK Algorithm ===\")\n","  return num_of_atoms, iteration, atom_sizes"],"metadata":{"id":"Bg037kV32zf9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from networkx.algorithms.cuts import node_expansion\n","from tqdm import tqdm\n","from functools import partial\n","tqdm = partial(tqdm, position=0, leave=True)\n","\n","def ch_partitioning_eval(G, LIMIT, eval_function):\n","  k = mc_lower_bound(G)\n","  og_bound = len(k)\n","  graph = k_core_reduction(G, len(k))\n","  og_size = len(G)\n","  eval_list = []\n","  node_eval_list = []\n","  best_eval = -10000\n","  best_node = 0\n","  for vertex in tqdm(list(G.nodes())):\n","    graph = G.copy()\n","    vertex_removals = {graph: []}\n","    SG = graph\n","    subgraphs = [graph]\n","    vcount = vertex_removals[SG]\n","    del vertex_removals[SG]\n","    SSG, SG = ch_partitioning(vertex, graph)\n","    SG = remove_zero_degree_nodes(SG)\n","    SSG = remove_zero_degree_nodes(SSG)\n","    SG = k_core_reduction(SG, len(k)-len(vcount)) #0\n","    SSG = k_core_reduction(SSG, len(k)-len(vcount+[vertex])) #1\n","    vertex_removals[SSG] = vcount+[vertex]\n","    vertex_removals[SG] = vcount\n","    #####################################################################################################\n","    if is_clique(G.subgraph(list(SSG.nodes()))) == True:\n","      assert is_clique(G.subgraph(list(SSG.nodes())+vertex_removals[SSG])) == True\n","      if len(SSG)+len(vertex_removals[SSG]) > len(k):\n","        k = list(SSG.nodes())+vertex_removals[SSG]\n","      del vertex_removals[SSG]\n","      SSG = nx.Graph()\n","    if is_clique(G.subgraph(list(SG.nodes()))) == True:\n","      assert is_clique(G.subgraph(list(SG.nodes())+vertex_removals[SG])) == True\n","      if len(SG)+len(vertex_removals[SG]) > len(k):\n","        k = list(SG.nodes())+vertex_removals[SG]\n","      del vertex_removals[SG]\n","      SG = nx.Graph()\n","    #####################################################################################################\n","    if len(SSG) != 0:\n","      SSG_lower = mc_lower_bound(SSG)+vertex_removals[SSG]\n","      #print(vertex_removals[SSG])\n","      assert is_clique(G.subgraph(SSG_lower)) == True\n","      if len(SSG_lower) > len(k):\n","        vcount = vertex_removals[SSG]\n","        del vertex_removals[SSG]\n","        k = SSG_lower\n","        SSG = k_core_reduction(SSG, len(k)-len(vcount))\n","        SSG = remove_zero_degree_nodes(SSG)\n","        vertex_removals[SSG] = vcount\n","      if len(SSG) != 0:\n","        SSG_upper = mc_upper_bound(SSG)+len(vertex_removals[SSG])\n","        if SSG_upper > len(k):\n","          if len(SSG) <= LIMIT:\n","            del vertex_removals[SSG]\n","          else:\n","            subgraphs.append(SSG)\n","        else:\n","          del vertex_removals[SSG]\n","    if len(SSG) == 0:\n","      if SSG in list(vertex_removals.keys()):\n","        sub_solution_SSG = vertex_removals[SSG]\n","        del vertex_removals[SSG]\n","        assert is_clique(G.subgraph(sub_solution_SSG)) == True\n","        if len(sub_solution_SSG) > len(k):\n","          k = sub_solution_SSG\n","    #####################################################################################################\n","    if len(SG) != 0:\n","      SG_lower = mc_lower_bound(SG)+vertex_removals[SG]\n","      #print(vertex_removals[SG])\n","      assert is_clique(G.subgraph(SG_lower)) == True\n","      if len(SG_lower) > len(k):\n","        vcount = vertex_removals[SG]\n","        del vertex_removals[SG]\n","        k = SG_lower\n","        SG = k_core_reduction(SG, len(k)-len(vcount))\n","        SG = remove_zero_degree_nodes(SG)\n","        vertex_removals[SG] = vcount\n","      if len(SG) != 0:\n","        SG_upper = mc_upper_bound(SG)+len(vertex_removals[SG])\n","        if SG_upper > len(k):\n","          if len(SG) <= LIMIT:\n","            del vertex_removals[SG]\n","          else:\n","            subgraphs.append(SG)\n","        else:\n","          del vertex_removals[SG]\n","    if len(SG) == 0:\n","      if SG in list(vertex_removals.keys()):\n","        sub_solution_SG = vertex_removals[SG]\n","        del vertex_removals[SG]\n","        assert is_clique(G.subgraph(sub_solution_SG)) == True\n","        if len(sub_solution_SG) > len(k):\n","          k = sub_solution_SG\n","    # define eval parameters\n","    SG_size =  len(SG)\n","    if SG_size <= LIMIT:\n","      SG_size = 0\n","    SSG_size = len(SSG)\n","    if SSG_size <= LIMIT:\n","      SSG_size = 0\n","    bound_improvement = len(k) - og_bound\n","    current_eval = eval_function(og_size, SG_size, SSG_size, bound_improvement)\n","    eval_list.append(current_eval)\n","    node_eval_list.append(vertex)\n","    if current_eval > best_eval:\n","      best_eval = current_eval\n","      best_node = vertex\n","  temp = [[x, y] for x, y in zip(node_eval_list, eval_list)]\n","  node_eval_list = temp\n","  return node_eval_list, best_eval, best_node"],"metadata":{"id":"oOsmkE5W7OmE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# DBK2 with the new eval functions\n","\n","def DBK2(graph, LIMIT, eval_function):\n","  \"\"\"\n","  INPUT:\n","    - \"graph\" must be a Networkx Undirected Graph\n","    - \"LIMIT\" is an integer describing the largest size of graph which solver_func can solve; all subgraph sizes solved will be less than or equal to LIMIT\n","    - \"solver_function\" takes a Networkx Graph, and outputs a list of nodes which are hopefully the Maximum Clique elements; it can be an approximate or exact solver function\n","  OUTPUT:\n","    - \"k\" is a list of graph nodes which form a clique in the input graph. If the solver is exact, then k is the Maximum Clique\n","  NOTES:\n","    - The central idea of using bounds is that we maintain a global lower bound on the Maximum Clique. Then, for each sub problem we calculate a fast upper bound.\n","      If any sub problem has an upper bound which is less than or equal to the global lower bound, we can remove that sub problem from consideration in the remaining iterations of the algorithm.\n","    - This algorithm does not necessarily enumerate all cliques nor all Maximum Cliques. In particular, it is designed to return a single maximum clique assuming the solver is exact.\n","      However, the algorithm could be modified to include all maximum cliques found from solving each sub-problem.\n","    - There are many assert statements in this function. These all serve as \"sanity checks\"; if any of them are tripped, something went wrong or an input was incorrect\n","  \"\"\"\n","  assert type(graph) is nx.Graph\n","  assert type(LIMIT) is int\n","  assert len(graph) != 0\n","  print(\"=== Starting DBK Algorithm ===\")\n","  G = graph.copy()\n","  num_of_atoms = 0\n","  iteration = 0\n","  atom_sizes = []\n","  if len(graph) <= LIMIT:\n","    print(\"=== Input Graph Size is Smaller than LIMIT ===\")\n","    num_of_atoms +=1\n","    print(\"=== Finished DBK Algorithm ===\")\n","    return num_of_atoms, iteration, atom_sizes\n","  print(\"Preprocessing...\")\n","  graph = remove_zero_degree_nodes(graph)\n","  k = mc_lower_bound(graph)\n","  graph = k_core_reduction(graph, len(k))\n","  if len(graph) == 0:\n","    return k\n","  if len(graph) <= LIMIT:\n","    print(\"=== After K-core Reduction the Graph Size is Smaller than LIMIT ===\")\n","    num_of_atoms += 1\n","    print(\"=== Finished DBK Algorithm ===\")\n","    return num_of_atoms, iteration, atom_sizes\n","  vertex_removal = {graph: []}\n","  subgraphs = [graph]\n","  while len(subgraphs) != 0:\n","    iteration += 1\n","    #print(\"Iteration number:\", iteration)\n","    SG = subgraphs.pop()\n","    SG = remove_zero_degree_nodes(SG)\n","    #print(\"Current subgraph size:\", len(SG))\n","    assert len(SG) != 0\n","    vcount = vertex_removal[SG]\n","    del vertex_removal[SG]\n","    #print(\"LOOKING FOR BEST VERTEX\")\n","    SG_copy = SG.copy()\n","    _,_,vertex = ch_partitioning_eval(SG_copy, LIMIT, average_node_decrease)\n","    SSG, SG = ch_partitioning(vertex, SG)\n","    SG = remove_zero_degree_nodes(SG) # BIG\n","    SSG = remove_zero_degree_nodes(SSG) # SMALL\n","    SG = k_core_reduction(SG, len(k)-len(vcount)) # 0\n","    SSG = k_core_reduction(SSG, len(k)-len(vcount+[vertex])) # 1\n","    vertex_removal[SSG] = vcount+[vertex]\n","    vertex_removal[SG] = vcount\n","    #####################################################################################################\n","    if is_clique(G.subgraph(list(SSG.nodes()))) == True:\n","      assert is_clique(G.subgraph(list(SSG.nodes())+vertex_removal[SSG])) == True\n","      if len(SSG)+len(vertex_removal[SSG]) > len(k):\n","        k = list(SSG.nodes())+vertex_removal[SSG]\n","      del vertex_removal[SSG]\n","      SSG = nx.Graph()\n","    if is_clique(G.subgraph(list(SG.nodes()))) == True:\n","      assert is_clique(G.subgraph(list(SG.nodes())+vertex_removal[SG])) == True\n","      if len(SG)+len(vertex_removal[SG]) > len(k):\n","        k = list(SG.nodes())+vertex_removal[SG]\n","      del vertex_removal[SG]\n","      SG = nx.Graph()\n","    #####################################################################################################\n","    if len(SSG) != 0:\n","      SSG_lower = mc_lower_bound(SSG)+vertex_removal[SSG]\n","      assert is_clique(G.subgraph(SSG_lower)) == True\n","      if len(SSG_lower) > len(k):\n","        vcount = vertex_removal[SSG]\n","        del vertex_removal[SSG]\n","        k = SSG_lower\n","        SSG = k_core_reduction(SSG, len(k)-len(vcount))\n","        SSG = remove_zero_degree_nodes(SSG)\n","        vertex_removal[SSG] = vcount\n","      if len(SSG) != 0:\n","        SSG_upper = mc_upper_bound(SSG)+len(vertex_removal[SSG])\n","        if SSG_upper > len(k):\n","          if len(SSG) <= LIMIT:\n","            #print(\"=== Terminal Subgraph Found ===\")\n","            #print(\"Size:\", len(SSG))\n","            atom_sizes.append(len(SSG))\n","            num_of_atoms += 1\n","            del vertex_removal[SSG]\n","          else:\n","            subgraphs.append(SSG)\n","        else:\n","          del vertex_removal[SSG]\n","    if len(SSG) == 0:\n","      if SSG in list(vertex_removal.keys()):\n","        sub_solution_SSG = vertex_removal[SSG]\n","        del vertex_removal[SSG]\n","        assert is_clique(G.subgraph(sub_solution_SSG)) == True\n","        if len(sub_solution_SSG) > len(k):\n","          k = sub_solution_SSG\n","    #####################################################################################################\n","    if len(SG) != 0:\n","      SG_lower = mc_lower_bound(SG)+vertex_removal[SG]\n","      assert is_clique(G.subgraph(SG_lower)) == True\n","      if len(SG_lower) > len(k):\n","        vcount = vertex_removal[SG]\n","        del vertex_removal[SG]\n","        k = SG_lower\n","        SG = k_core_reduction(SG, len(k)-len(vcount))\n","        SG = remove_zero_degree_nodes(SG)\n","        vertex_removal[SG] = vcount\n","      if len(SG) != 0:\n","        SG_upper = mc_upper_bound(SG)+len(vertex_removal[SG])\n","        if SG_upper > len(k):\n","          if len(SG) <= LIMIT:\n","            #print(\"=== Terminal Subgraph Found ===\")\n","            #print(\"Size:\", len(SG))\n","            atom_sizes.append(len(SG))\n","            num_of_atoms += 1\n","            # sub_solution_SG = solver_function(SG)+vertex_removal[SG]\n","            del vertex_removal[SG]\n","          else:\n","            subgraphs.append(SG)\n","        else:\n","          del vertex_removal[SG]\n","    if len(SG) == 0:\n","      if SG in list(vertex_removal.keys()):\n","        sub_solution_SG = vertex_removal[SG]\n","        del vertex_removal[SG]\n","        assert is_clique(G.subgraph(sub_solution_SG)) == True\n","        if len(sub_solution_SG) > len(k):\n","          k = sub_solution_SG\n","  assert len(vertex_removal) == 0\n","  print(\"=== Finished DBK Algorithm ===\")\n","  return num_of_atoms, iteration, atom_sizes"],"metadata":{"id":"M8ddAu7n7ait"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install torch_geometric"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"OfXbxHjAITBO","executionInfo":{"status":"ok","timestamp":1702414002867,"user_tz":300,"elapsed":2309,"user":{"displayName":"Jia He Sun","userId":"07783893916712904513"}},"outputId":"afa8440a-c7a9-473f-9695-5ac68ed83a58"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch_geometric in /usr/local/lib/python3.10/dist-packages (2.4.0)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (4.66.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.23.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.11.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (2.31.0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (3.1.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (1.2.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch_geometric) (5.9.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch_geometric) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.2.0)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (3.4)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch_geometric) (2023.7.22)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch_geometric) (3.2.0)\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import networkx as nx\n","from torch_geometric.data import Data\n","import numpy as np\n","\n","# Defining some data preprocessing functions\n","def graph_to_pyg_data(graph):\n","    edge_index = torch.tensor(list(graph.edges)).t().contiguous()\n","    x = torch.eye(graph.number_of_nodes())  # Node features, identity matrix in this example\n","    y = torch.tensor(list(nx.get_node_attributes(graph, 'label').values()))  # Node labels\n","\n","    return Data(x=x, edge_index=edge_index, y=y)\n","\n","def to_networkx(data):\n","    edge_index = data.edge_index.cpu().numpy()\n","    edge_attr = None\n","    if data.edge_attr is not None:\n","        edge_attr = data.edge_attr.cpu().numpy()\n","\n","    G = nx.Graph()\n","    G.add_nodes_from(range(data.num_nodes))\n","    G.add_edges_from(edge_index.T)\n","\n","    if edge_attr is not None:\n","        for i, (src, tgt) in enumerate(edge_index.T):\n","            G[src][tgt]['edge_attr'] = edge_attr[i]\n","\n","    return G\n","\n","    # min max normalize [0, 1]\n","def min_max_normalize(data, new_min=0, new_max=1):\n","    # Find the min and max values in the data\n","    min_val = min(data)\n","    max_val = max(data)\n","    if min_val == max_val:\n","      return [1 for _ in range(len(data))]\n","    normalized_data = [(x - min_val) / (max_val - min_val) * (new_max - new_min) + new_min for x in data]\n","    return normalized_data\n","\n","# top k% of values are 1 rest are 0\n","def top_k(label_list, k):\n","    k = round(k*len(label_list))\n","    input_list = min_max_normalize(label_list)\n","    # Sort the list in descending order\n","    sorted_list = sorted(input_list, reverse=True)\n","    # Determine the threshold index\n","    threshold_index = min(k, len(sorted_list))\n","    # Set the first k elements to 1 and the rest to 0\n","    thresholded_list = [1 if i < threshold_index else 0 for i in range(len(sorted_list))]\n","    # Create a mapping from original indices to sorted indices\n","    index_mapping = {original: sorted_index for sorted_index, original in enumerate(sorted(range(len(input_list)), key=lambda x: input_list[x], reverse=True))}\n","    # Sort the thresholded list back to the original order\n","    thresholded_list_original_order = [thresholded_list[index_mapping[i]] for i in range(len(input_list))]\n","\n","    return thresholded_list_original_order\n","\n","# continuous [0,1]\n","def continuous(label_list, k):\n","  label_list = min_max_normalize(label_list)\n","  return label_list\n","\n","# value above k are 1 rest are 0\n","def within_k(label_list, k):\n","  k = 1-k\n","  label_list = min_max_normalize(label_list)\n","  data = [1 if x > k else 0 for x in label_list]\n","  return data"],"metadata":{"id":"FQeuSjLZ7u1J"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# SOME EVALUATION FUNCTIONS\n","\n","# average of |G| - |SG| and |G| - |SSG|\n","def average_node_decrease(original_graph_size, subgraph1_size, subgraph2_size, bound_improve):\n","  if subgraph1_size == 0 and subgraph2_size == 0:\n","    return original_graph_size\n","  elif subgraph1_size == 0:\n","    return original_graph_size - subgraph2_size\n","  elif subgraph2_size == 0:\n","    return original_graph_size - subgraph1_size\n","  else:\n","    return (2*original_graph_size - subgraph2_size - subgraph1_size)/2\n","\n","# average of |G| - |SG| and |G| - |SSG| PLUS bound improvement\n","def average_node_decrease_with_bound(original_graph_size, subgraph1_size, subgraph2_size, bound_improve):\n","  if subgraph1_size == 0 and subgraph2_size == 0:\n","    return original_graph_size + bound_improve\n","  elif subgraph1_size == 0:\n","    return original_graph_size - subgraph2_size + bound_improve\n","  elif subgraph2_size == 0:\n","    return original_graph_size - subgraph1_size + bound_improve\n","  else:\n","    return (2*original_graph_size - subgraph2_size - subgraph1_size)/2 + bound_improve\n","\n","# total node decrease\n","def total_node_decrease(original_graph_size, subgraph1_size, subgraph2_size, bound_improve):\n","  return 2*original_graph_size - subgraph1_size - subgraph2_size\n","\n","# total node decrease PLUS bound improvement\n","def total_node_decrease(original_graph_size, subgraph1_size, subgraph2_size, bound_improve):\n","  return 2*original_graph_size - subgraph1_size - subgraph2_size + bound_improve\n","\n","# max node decrease\n","def max_node_decrease(original_graph_size, subgraph1_size, subgraph2_size, bound_improve):\n","  return original_graph_size - max(subgraph1_size, subgraph2_size)\n","\n","# bound improvement\n","def total_bound_improvement(original_graph_size, subgraph1_size, subgraph2_size, bound_improve):\n","  return bound_improve\n","\n"],"metadata":{"id":"giFIAmo_8_52"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Generating Labels Function\n","def label_generation(graph, LIMIT, eval_function=average_node_decrease):\n","  \"\"\"\n","  Input: networkx graph, decomposition LIMIT\n","  - Preprocess graph (kcore)\n","  - Assign labels to each node\n","  Output: networkx graph with node labels\n","  \"\"\"\n","  assert type(graph) is nx.Graph\n","  assert type(LIMIT) is int\n","  assert len(graph) != 0\n","  print(\"=== Starting Labelling Algorithm ===\")\n","  G = graph.copy()\n","  atom_sizes = []\n","  if len(graph) <= LIMIT:\n","    print(\"=== Input Graph Size is Smaller than LIMIT ===\")\n","    return\n","  print(\"Preprocessing...\")\n","  graph = remove_zero_degree_nodes(graph)\n","  k = mc_lower_bound(graph)\n","  vertex_removal = {graph: []}\n","  subgraphs = [graph]\n","  SG = subgraphs.pop()\n","  SG = remove_zero_degree_nodes(SG)\n","  assert len(SG) != 0\n","  vcount = vertex_removal[SG]\n","  del vertex_removal[SG]\n","  print(\"Computing Labels\")\n","  SG_copy = SG.copy()\n","  eval_list,_,_ = ch_partitioning_eval(SG_copy, LIMIT, eval_function)\n","  for node_eval in eval_list:\n","    node = node_eval[0]\n","    eval = node_eval[1]\n","    G.nodes[node]['label'] = eval\n","  return G\n","\n","# Normalize dataset function\n","def dataset_normalize(dataset, normalize_function, normalize_param):\n","  for graph_idx in tqdm(range(len(dataset))):\n","    data = dataset[graph_idx]\n","    node_labels_list = data.y.tolist()\n","    normalized_node_labels_list = normalize_function(node_labels_list, normalize_param)\n","    data.y = torch.tensor(normalized_node_labels_list)\n","  return dataset"],"metadata":{"id":"VcKCpIpz7zBc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TAKES IN A NETWORKX GRAPH AND OUTPUTS A TENSOR THAT IS THE NODE FEATURES\n","def get_features(nxgraph):\n","  # get features\n","  node_degrees = dict(nxgraph.degree())\n","  degree_centrality = nx.degree_centrality(nxgraph)\n","  betweenness_centrality = nx.betweenness_centrality(nxgraph)\n","  closeness_centrality = nx.closeness_centrality(nxgraph)\n","  eigenvector_centrality = nx.eigenvector_centrality(nxgraph)\n","  pagerank_centrality = nx.pagerank(nxgraph)\n","  harmonic_centrality = nx.harmonic_centrality(nxgraph)\n","  load_centrality = nx.load_centrality(nxgraph)\n","  clustering_coefficient = nx.clustering(nxgraph)\n","  # make it into an array\n","  features_array = np.array([\n","    list(node_degrees.values()),\n","    list(degree_centrality.values()),\n","    list(betweenness_centrality.values()),\n","    list(closeness_centrality.values()),\n","    list(eigenvector_centrality.values()),\n","    list(pagerank_centrality.values()),\n","    list(harmonic_centrality.values()),\n","    list(load_centrality.values()),\n","    list(clustering_coefficient.values())])\n","  features_array = features_array.T\n","  return torch.tensor(features_array)\n"],"metadata":{"id":"r98-E4dCA5f1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TRAINING DATASET GENERATION\n","LIMIT = 40\n","labeled_dataset = []\n","eval_function = average_node_decrease\n","number_of_graphs = 500\n","print(\"Preprocessing and Generating Labels...\")\n","for i in tqdm(range(number_of_graphs)):\n","  G = nx.gnp_random_graph(200, random.uniform(0.3, 0.9))\n","  labeled_graph = label_generation(G, LIMIT=LIMIT, eval_function=eval_function)\n","  if labeled_graph is None:\n","    continue\n","  #feature_tensor = get_features(labeled_graph)\n","  final_graph = graph_to_pyg_data(labeled_graph)\n","  #final_graph.x = feature_tensor\n","  labeled_dataset.append(final_graph)\n","  print(final_graph)\n","\n","torch.save(labeled_dataset, \"/content/datasets/train_200nodes_500graphs.pt\")"],"metadata":{"id":"lJewpb1N9RYS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TEST SET 200 nodes different densities\n","LIMIT = 40\n","labeled_dataset = []\n","eval_function = average_node_decrease\n","number_of_graphs = 10\n","print(\"Preprocessing and Generating Labels...\")\n","for i in tqdm(range(number_of_graphs)):\n","  G = nx.gnp_random_graph(80, random.uniform(0.1, 0.7))\n","  labeled_graph = label_generation(G, LIMIT=LIMIT, eval_function=eval_function)\n","  if labeled_graph is None:\n","    continue\n","  #feature_tensor = get_features(labeled_graph)\n","  final_graph = graph_to_pyg_data(labeled_graph)\n","  #final_graph.x = feature_tensor\n","  labeled_dataset.append(final_graph)\n","  print(final_graph)\n","\n","torch.save(labeled_dataset, \"/content/test_80nodes_10graphs.pt\")"],"metadata":{"id":"T-R5i-poW3_9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1702414042740,"user_tz":300,"elapsed":22700,"user":{"displayName":"Jia He Sun","userId":"07783893916712904513"}},"outputId":"e2953833-f12b-4bf1-c178-2d56b333e078"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Preprocessing and Generating Labels...\n"]},{"output_type":"stream","name":"stderr","text":["\r  0%|          | 0/10 [00:00<?, ?it/s]"]},{"output_type":"stream","name":"stdout","text":["=== Starting Labelling Algorithm ===\n","Preprocessing...\n","Computing Labels\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 80/80 [00:03<00:00, 24.37it/s]\n"," 10%|█         | 1/10 [00:03<00:29,  3.31s/it]"]},{"output_type":"stream","name":"stdout","text":["Data(x=[80, 80], edge_index=[2, 2045], y=[80])\n","=== Starting Labelling Algorithm ===\n","Preprocessing...\n","Computing Labels\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 80/80 [00:03<00:00, 24.99it/s]\n"," 20%|██        | 2/10 [00:06<00:26,  3.27s/it]"]},{"output_type":"stream","name":"stdout","text":["Data(x=[80, 80], edge_index=[2, 2099], y=[80])\n","=== Starting Labelling Algorithm ===\n","Preprocessing...\n","Computing Labels\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 80/80 [00:01<00:00, 61.47it/s]\n"," 30%|███       | 3/10 [00:07<00:16,  2.38s/it]"]},{"output_type":"stream","name":"stdout","text":["Data(x=[80, 80], edge_index=[2, 930], y=[80])\n","=== Starting Labelling Algorithm ===\n","Preprocessing...\n","Computing Labels\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 80/80 [00:03<00:00, 20.75it/s]\n"," 40%|████      | 4/10 [00:11<00:17,  2.98s/it]"]},{"output_type":"stream","name":"stdout","text":["Data(x=[80, 80], edge_index=[2, 1128], y=[80])\n","=== Starting Labelling Algorithm ===\n","Preprocessing...\n","Computing Labels\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 80/80 [00:00<00:00, 144.08it/s]\n"," 50%|█████     | 5/10 [00:12<00:10,  2.12s/it]"]},{"output_type":"stream","name":"stdout","text":["Data(x=[80, 80], edge_index=[2, 778], y=[80])\n","=== Starting Labelling Algorithm ===\n","Preprocessing...\n","Computing Labels\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 80/80 [00:02<00:00, 27.71it/s]\n"," 60%|██████    | 6/10 [00:15<00:09,  2.39s/it]"]},{"output_type":"stream","name":"stdout","text":["Data(x=[80, 80], edge_index=[2, 1750], y=[80])\n","=== Starting Labelling Algorithm ===\n","Preprocessing...\n","Computing Labels\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 80/80 [00:00<00:00, 90.92it/s]\n"," 70%|███████   | 7/10 [00:16<00:05,  1.91s/it]"]},{"output_type":"stream","name":"stdout","text":["Data(x=[80, 80], edge_index=[2, 909], y=[80])\n","=== Starting Labelling Algorithm ===\n","Preprocessing...\n","Computing Labels\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 80/80 [00:01<00:00, 53.24it/s]\n"," 80%|████████  | 8/10 [00:17<00:03,  1.79s/it]"]},{"output_type":"stream","name":"stdout","text":["Data(x=[80, 80], edge_index=[2, 987], y=[80])\n","=== Starting Labelling Algorithm ===\n","Preprocessing...\n","Computing Labels\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 80/80 [00:03<00:00, 25.29it/s]\n"," 90%|█████████ | 9/10 [00:20<00:02,  2.23s/it]"]},{"output_type":"stream","name":"stdout","text":["Data(x=[80, 80], edge_index=[2, 1579], y=[80])\n","=== Starting Labelling Algorithm ===\n","Preprocessing...\n","Computing Labels\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 80/80 [00:01<00:00, 48.65it/s]\n","100%|██████████| 10/10 [00:22<00:00,  2.26s/it]"]},{"output_type":"stream","name":"stdout","text":["Data(x=[80, 80], edge_index=[2, 989], y=[80])\n"]},{"output_type":"stream","name":"stderr","text":["\n"]}]},{"cell_type":"code","source":["# VAL SET 200 nodes different densities\n","LIMIT = 40\n","labeled_dataset = []\n","eval_function = average_node_decrease\n","number_of_graphs = 200\n","print(\"Preprocessing and Generating Labels...\")\n","for i in tqdm(range(number_of_graphs)):\n","  G = nx.gnp_random_graph(200, random.uniform(0.1, 0.7))\n","  labeled_graph = label_generation(G, LIMIT=LIMIT, eval_function=eval_function)\n","  if labeled_graph is None:\n","    continue\n","  #feature_tensor = get_features(labeled_graph)\n","  final_graph = graph_to_pyg_data(labeled_graph)\n","  #final_graph.x = feature_tensor\n","  labeled_dataset.append(final_graph)\n","  print(final_graph)\n","\n","torch.save(labeled_dataset, \"/content/datasets/val_200nodes_200graphs.pt\")"],"metadata":{"id":"gZ6_6d4JFJRL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# TEST SET 300/400/500 nodes 0.5 density\n","LIMIT = 40\n","labeled_dataset = []\n","eval_function = average_node_decrease\n","number_of_graphs = 10\n","print(\"Preprocessing and Generating Labels...\")\n","for i in tqdm(range(number_of_graphs)):\n","  G = nx.gnp_random_graph(300, 0.5)\n","  labeled_graph = label_generation(G, LIMIT=LIMIT, eval_function=eval_function)\n","  if labeled_graph is None:\n","    continue\n","  #feature_tensor = get_features(labeled_graph)\n","  final_graph = graph_to_pyg_data(labeled_graph)\n","  #final_graph.x = feature_tensor\n","  labeled_dataset.append(final_graph)\n","  print(final_graph)\n","\n","torch.save(labeled_dataset, \"/content/datasets/test_300nodes_10graphs.pt\")\n","\n","labeled_dataset = []\n","for i in tqdm(range(number_of_graphs)):\n","  G = nx.gnp_random_graph(400, 0.5)\n","  labeled_graph = label_generation(G, LIMIT=LIMIT, eval_function=eval_function)\n","  if labeled_graph is None:\n","    continue\n","  #feature_tensor = get_features(labeled_graph)\n","  final_graph = graph_to_pyg_data(labeled_graph)\n","  #final_graph.x = feature_tensor\n","  labeled_dataset.append(final_graph)\n","  print(final_graph)\n","\n","torch.save(labeled_dataset, \"/content/datasets/test_400nodes_10graphs.pt\")\n","\n","labeled_dataset = []\n","for i in tqdm(range(number_of_graphs)):\n","  G = nx.gnp_random_graph(500, 0.5)\n","  labeled_graph = label_generation(G, LIMIT=LIMIT, eval_function=eval_function)\n","  if labeled_graph is None:\n","    continue\n","  #feature_tensor = get_features(labeled_graph)\n","  final_graph = graph_to_pyg_data(labeled_graph)\n","  #final_graph.x = feature_tensor\n","  labeled_dataset.append(final_graph)\n","  print(final_graph)\n","\n","torch.save(labeled_dataset, \"/content/datasets/test_500nodes_10graphs.pt\")"],"metadata":{"id":"YjiMqUOUHMu5"},"execution_count":null,"outputs":[]}]}