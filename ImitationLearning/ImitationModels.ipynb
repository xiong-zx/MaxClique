{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"machine_shape":"hm","authorship_tag":"ABX9TyModTI5kTvK0TtOpnUIdu2m"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"09f3695e87aa4942881b538bc79a8f6a":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5744a61017b940329c8c9f1ad16dbc40","IPY_MODEL_875c6aa35b564c08a99bbbc0511698ad","IPY_MODEL_1eaa357c673345f6b1c785597e012971"],"layout":"IPY_MODEL_b67755ce325b4851be0c265b85762a1a"}},"5744a61017b940329c8c9f1ad16dbc40":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_95ce7c7a90da4ee7a5faa2e1925fdce5","placeholder":"​","style":"IPY_MODEL_473b7607761640339d5a31679cbd5224","value":"100%"}},"875c6aa35b564c08a99bbbc0511698ad":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_621412dc05634d03882bc3bddbc61bef","max":200,"min":0,"orientation":"horizontal","style":"IPY_MODEL_14e695f0f83c4a508348db6d373070b4","value":200}},"1eaa357c673345f6b1c785597e012971":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_db396593e501445a864e43ab366850f5","placeholder":"​","style":"IPY_MODEL_4b9cb8e0512c4aacb67e97a191ee4006","value":" 200/200 [00:00&lt;00:00, 3075.80it/s]"}},"b67755ce325b4851be0c265b85762a1a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"95ce7c7a90da4ee7a5faa2e1925fdce5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"473b7607761640339d5a31679cbd5224":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"621412dc05634d03882bc3bddbc61bef":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"14e695f0f83c4a508348db6d373070b4":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"db396593e501445a864e43ab366850f5":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"4b9cb8e0512c4aacb67e97a191ee4006":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2a41e2495c5b4a1385343c6580fded54":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_4bfa1f071b314fdda7994aad38099b16","IPY_MODEL_d3eb4a8dcdeb495790c68834c2325db1","IPY_MODEL_69433f1a96534888aa4000abb9fe1b0b"],"layout":"IPY_MODEL_ab17fd7d20bd4e59af9b78a32483dfed"}},"4bfa1f071b314fdda7994aad38099b16":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ac5faaf6b6e4092842015974a8d0300","placeholder":"​","style":"IPY_MODEL_34dc8f7192be4905a2005db8e2b6db03","value":"100%"}},"d3eb4a8dcdeb495790c68834c2325db1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_b9a3bfdbc5294fca93f4e1452ebeee7a","max":200,"min":0,"orientation":"horizontal","style":"IPY_MODEL_ad7fedb4ceb9473cbec924da39f982db","value":200}},"69433f1a96534888aa4000abb9fe1b0b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8cfb5f599dd24a8d831ba3cbfdc8f0be","placeholder":"​","style":"IPY_MODEL_7b19b2b47ea54accb2d85a8cf55a07b9","value":" 200/200 [14:41&lt;00:00,  4.32s/it]"}},"ab17fd7d20bd4e59af9b78a32483dfed":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ac5faaf6b6e4092842015974a8d0300":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"34dc8f7192be4905a2005db8e2b6db03":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b9a3bfdbc5294fca93f4e1452ebeee7a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ad7fedb4ceb9473cbec924da39f982db":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8cfb5f599dd24a8d831ba3cbfdc8f0be":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7b19b2b47ea54accb2d85a8cf55a07b9":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"onqwBVDn1fdu","executionInfo":{"status":"ok","timestamp":1702407297576,"user_tz":300,"elapsed":11891,"user":{"displayName":"Jia He Sun","userId":"07783893916712904513"}},"outputId":"c8169924-e596-4998-d642-ba9e96b6f4b4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["!pip install torch torchvision torchaudio\n","!pip install torch-geometric\n","!pip install torchviz"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UEqFUaZN1mSC","executionInfo":{"status":"ok","timestamp":1702407318317,"user_tz":300,"elapsed":20743,"user":{"displayName":"Jia He Sun","userId":"07783893916712904513"}},"outputId":"ff263de0-76dc-43f6-f96a-790a9e42ae8c"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n","Requirement already satisfied: torchvision in /usr/local/lib/python3.10/dist-packages (0.16.0+cu118)\n","Requirement already satisfied: torchaudio in /usr/local/lib/python3.10/dist-packages (2.1.0+cu118)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.1.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torchvision) (1.23.5)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torchvision) (2.31.0)\n","Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision) (9.4.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torchvision) (2023.11.17)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n","Collecting torch-geometric\n","  Downloading torch_geometric-2.4.0-py3-none-any.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (4.66.1)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.23.5)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.11.4)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.2)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (2.31.0)\n","Requirement already satisfied: pyparsing in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (3.1.1)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (1.2.2)\n","Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.10/dist-packages (from torch-geometric) (5.9.5)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch-geometric) (2.1.3)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2.0.7)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->torch-geometric) (2023.11.17)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->torch-geometric) (3.2.0)\n","Installing collected packages: torch-geometric\n","Successfully installed torch-geometric-2.4.0\n","Collecting torchviz\n","  Downloading torchviz-0.0.2.tar.gz (4.9 kB)\n","  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torchviz) (2.1.0+cu118)\n","Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from torchviz) (0.20.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.13.1)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (4.5.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (1.12)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.2.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (3.1.2)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2023.6.0)\n","Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch->torchviz) (2.1.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torchviz) (2.1.3)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torchviz) (1.3.0)\n","Building wheels for collected packages: torchviz\n","  Building wheel for torchviz (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for torchviz: filename=torchviz-0.0.2-py3-none-any.whl size=4131 sha256=01e1c2afef1e1916ec0ca1efcb57da3c3099c5fcd1619b8e6ad258d159fbf54f\n","  Stored in directory: /root/.cache/pip/wheels/4c/97/88/a02973217949e0db0c9f4346d154085f4725f99c4f15a87094\n","Successfully built torchviz\n","Installing collected packages: torchviz\n","Successfully installed torchviz-0.0.2\n"]}]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import matplotlib.pyplot as plt\n","from torch_geometric.nn import GCNConv\n","import torch.nn.functional as F\n","from torch_geometric.datasets import GNNBenchmarkDataset\n","import torch_geometric.nn as geo_nn\n","from torch_geometric.data import DataLoader\n","import networkx as nx\n","import torch_geometric.transforms as T\n","from torch_geometric.nn import GCNConv, global_mean_pool\n","from torch_geometric.data import Data\n","from torch_geometric.transforms import Constant\n","from tqdm.auto import tqdm\n","from itertools import combinations\n","import numpy as np"],"metadata":{"id":"ClMHShOn3AfV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#  HELPERS"],"metadata":{"id":"sqgxmYrK5wM2"}},{"cell_type":"code","source":["\n","# Defining some data preprocessing functions\n","def graph_to_pyg_data(graph):\n","    edge_index = torch.tensor(list(graph.edges)).t().contiguous()\n","    x = torch.eye(graph.number_of_nodes())  # Node features, identity matrix in this example\n","    y = torch.tensor(list(nx.get_node_attributes(graph, 'label').values()))  # Node labels\n","\n","    return Data(x=x, edge_index=edge_index, y=y)\n","\n","def to_networkx(data):\n","    edge_index = data.edge_index.cpu().numpy()\n","    edge_attr = None\n","    if data.edge_attr is not None:\n","        edge_attr = data.edge_attr.cpu().numpy()\n","\n","    G = nx.Graph()\n","    G.add_nodes_from(range(data.num_nodes))\n","    G.add_edges_from(edge_index.T)\n","\n","    if edge_attr is not None:\n","        for i, (src, tgt) in enumerate(edge_index.T):\n","            G[src][tgt]['edge_attr'] = edge_attr[i]\n","\n","    return G\n","\n","    # min max normalize [0, 1]\n","def min_max_normalize(data, new_min=0, new_max=1):\n","    # Find the min and max values in the data\n","    min_val = min(data)\n","    max_val = max(data)\n","    if min_val == max_val:\n","      return [1 for _ in range(len(data))]\n","    normalized_data = [(x - min_val) / (max_val - min_val) * (new_max - new_min) + new_min for x in data]\n","    return normalized_data\n","\n","# top k% of values are 1 rest are 0\n","def top_k(label_list, k):\n","    k = round(k*len(label_list))\n","    input_list = min_max_normalize(label_list)\n","    # Sort the list in descending order\n","    sorted_list = sorted(input_list, reverse=True)\n","    # Determine the threshold index\n","    threshold_index = min(k, len(sorted_list))\n","    # Set the first k elements to 1 and the rest to 0\n","    thresholded_list = [1 if i < threshold_index else 0 for i in range(len(sorted_list))]\n","    # Create a mapping from original indices to sorted indices\n","    index_mapping = {original: sorted_index for sorted_index, original in enumerate(sorted(range(len(input_list)), key=lambda x: input_list[x], reverse=True))}\n","    # Sort the thresholded list back to the original order\n","    thresholded_list_original_order = [thresholded_list[index_mapping[i]] for i in range(len(input_list))]\n","\n","    return thresholded_list_original_order\n","\n","# continuous [0,1]\n","def continuous(label_list, k):\n","  label_list = min_max_normalize(label_list)\n","  return label_list\n","\n","# value above k are 1 rest are 0\n","def within_k(label_list, k):\n","  k = 1-k\n","  label_list = min_max_normalize(label_list)\n","  data = [1 if x > k else 0 for x in label_list]\n","  return data\n","\n","\n","def max_normalize_binary(label_list, k):\n","  k = 1-k\n","  # normalize data\n","  max_val = max(label_list)\n","  normalized_data = [(x / max_val) for x in label_list]\n","  data = [1 if x > k else 0 for x in normalized_data]\n","  return data\n","\n","def max_normalize(label_list, k):\n","  # normalize data\n","  max_val = max(label_list)\n","  normalized_data = [(x / max_val) for x in label_list]\n","  return normalized_data\n","\n","# Normalize dataset function\n","def dataset_normalize(dataset, normalize_function, normalize_param):\n","  for graph_idx in tqdm(range(len(dataset))):\n","    data = dataset[graph_idx]\n","    node_labels_list = data.y.tolist()\n","    normalized_node_labels_list = normalize_function(node_labels_list, normalize_param)\n","    data.y = torch.tensor(normalized_node_labels_list)\n","  return dataset\n","\n","# TAKES IN A NETWORKX GRAPH AND OUTPUTS A TENSOR THAT IS THE NODE FEATURES\n","def get_features(nxgraph):\n","  # get features\n","  node_degrees = dict(nxgraph.degree())\n","  degree_centrality = nx.degree_centrality(nxgraph)\n","  betweenness_centrality = nx.betweenness_centrality(nxgraph)\n","  closeness_centrality = nx.closeness_centrality(nxgraph)\n","  eigenvector_centrality = nx.eigenvector_centrality(nxgraph)\n","  pagerank_centrality = nx.pagerank(nxgraph)\n","  harmonic_centrality = nx.harmonic_centrality(nxgraph)\n","  load_centrality = nx.load_centrality(nxgraph)\n","  clustering_coefficient = nx.clustering(nxgraph)\n","  # make it into an array\n","  features_array = np.array([\n","    list(node_degrees.values()),\n","    list(degree_centrality.values()),\n","    list(betweenness_centrality.values()),\n","    list(closeness_centrality.values()),\n","    list(eigenvector_centrality.values()),\n","    list(pagerank_centrality.values()),\n","    list(harmonic_centrality.values()),\n","    list(load_centrality.values()),\n","    list(clustering_coefficient.values())])\n","  features_array = features_array.T\n","  return torch.tensor(features_array, dtype=torch.float32)\n"],"metadata":{"id":"EqMxX7yB5xm6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# GCN Layer\n","\n","class GCNLayer(nn.Module):\n","    def __init__(self, input_size, hidden_size):\n","        super(GCNLayer, self).__init__()\n","        self.gcn = GCNConv(input_size, hidden_size)\n","\n","    def forward(self, x, edge_index):\n","        return self.gcn(x, edge_index)\n"],"metadata":{"id":"V8A2ujNU29_N"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Dataset\n","\n","class PairwiseRankingDataset(Dataset):\n","    def __init__(self, features, labels):\n","        self.features = features\n","        self.labels = labels\n","\n","    def __len__(self):\n","        return len(self.features)\n","\n","    def __getitem__(self, idx):\n","        return self.features[idx], self.labels[idx]"],"metadata":{"id":"pqPu2Wla3qs1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load training data\n","loaded_dataset = torch.load('/content/drive/MyDrive/Colab Notebooks/Decomp/LabeledData/NetworkxGraphs/train_200nodes_500graphs.pt')\n","normalize_function = max_normalize_binary\n","normalize_param = 0.2 # top 20% of nodes are 1 rest are 0\n","dataset_normalize(loaded_dataset, normalize_function=normalize_function, normalize_param=normalize_param)\n","labels = torch.empty(0, dtype=torch.float32)\n","features = torch.empty(0, dtype=torch.float32)\n","for graph in tqdm(loaded_dataset):\n","    temp_labels = graph.y\n","    labels = torch.cat([labels, temp_labels], dim=0)\n","    graph.x = get_features(to_networkx(graph))\n","    temp_features = graph.x\n","    features = torch.cat([features, temp_features], dim=0)\n","\n","print(labels.shape)\n","print(features.shape)\n","\n","train_graphs = loaded_dataset\n","torch.save(train_graphs, '/content/drive/MyDrive/Colab Notebooks/Decomp/LabeledData/NetworkxGraphs/train_200nodes_500graphs_features.pt')"],"metadata":{"id":"25OFgpFZ4DKJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Load val data\n","loaded_dataset = torch.load('/content/drive/MyDrive/Colab Notebooks/Decomp/LabeledData/NetworkxGraphs/val_200nodes_200graphs.pt')\n","normalize_function = max_normalize_binary\n","normalize_param = 0.2 # top 20% of nodes are 1 rest are 0\n","dataset_normalize(loaded_dataset, normalize_function=normalize_function, normalize_param=normalize_param)\n","labels = torch.empty(0, dtype=torch.float32)\n","features = torch.empty(0, dtype=torch.float32)\n","for graph in tqdm(loaded_dataset):\n","    temp_labels = graph.y\n","    labels = torch.cat([labels, temp_labels], dim=0)\n","    graph.x = get_features(to_networkx(graph))\n","    temp_features = graph.x\n","    features = torch.cat([features, temp_features], dim=0)\n","\n","print(labels.shape)\n","print(features.shape)\n","\n","val_graphs = loaded_dataset\n","torch.save(val_graphs, '/content/drive/MyDrive/Colab Notebooks/Decomp/LabeledData/NetworkxGraphs/val_200nodes_200graphs_features.pt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":116,"referenced_widgets":["09f3695e87aa4942881b538bc79a8f6a","5744a61017b940329c8c9f1ad16dbc40","875c6aa35b564c08a99bbbc0511698ad","1eaa357c673345f6b1c785597e012971","b67755ce325b4851be0c265b85762a1a","95ce7c7a90da4ee7a5faa2e1925fdce5","473b7607761640339d5a31679cbd5224","621412dc05634d03882bc3bddbc61bef","14e695f0f83c4a508348db6d373070b4","db396593e501445a864e43ab366850f5","4b9cb8e0512c4aacb67e97a191ee4006","2a41e2495c5b4a1385343c6580fded54","4bfa1f071b314fdda7994aad38099b16","d3eb4a8dcdeb495790c68834c2325db1","69433f1a96534888aa4000abb9fe1b0b","ab17fd7d20bd4e59af9b78a32483dfed","8ac5faaf6b6e4092842015974a8d0300","34dc8f7192be4905a2005db8e2b6db03","b9a3bfdbc5294fca93f4e1452ebeee7a","ad7fedb4ceb9473cbec924da39f982db","8cfb5f599dd24a8d831ba3cbfdc8f0be","7b19b2b47ea54accb2d85a8cf55a07b9"]},"id":"YhQFub19L-EE","executionInfo":{"status":"ok","timestamp":1702090304364,"user_tz":300,"elapsed":881903,"user":{"displayName":"Jia He Sun","userId":"07783893916712904513"}},"outputId":"25377188-21a6-4920-d63b-45061ad616a8"},"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/200 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"09f3695e87aa4942881b538bc79a8f6a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["  0%|          | 0/200 [00:00<?, ?it/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a41e2495c5b4a1385343c6580fded54"}},"metadata":{}},{"output_type":"stream","name":"stdout","text":["torch.Size([40000])\n","torch.Size([40000, 9])\n"]}]},{"cell_type":"code","source":["train_graphs = torch.load('/content/drive/MyDrive/Colab Notebooks/Decomp/LabeledData/NetworkxGraphs/train_200nodes_500graphs_features.pt')\n","val_graphs = torch.load('/content/drive/MyDrive/Colab Notebooks/Decomp/LabeledData/NetworkxGraphs/val_200nodes_200graphs_features.pt')"],"metadata":{"id":"kYg2Z1tlxVtT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torchviz import make_dot\n","from IPython.display import Image\n","\n","batch_size = 2\n","epochs = 50\n","input_size = 9\n","gcn_hidden_size = 256\n","model = SimpleRankModel(input_size, gcn_hidden_size)\n","\n","# Dummy input\n","dummy_input = train_graphs[0]\n","\n","# Generate a graph of the model architecture\n","graph = make_dot(model(dummy_input), params=dict(model.named_parameters()))\n","\n","# Save the graph to a file (e.g., PNG)\n","graph.render(\"model_graph\", format=\"png\", cleanup=True)\n","\n","# Display the saved image\n","Image(\"model_graph.png\")"],"metadata":{"id":"zc9kYUWVoY4c"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Simple Rank"],"metadata":{"id":"wmQ8vho13D3U"}},{"cell_type":"code","source":["class SimpleRankModel(nn.Module):\n","    def __init__(self, input_size, gcn_hidden_size, dropout_prob=0.2):\n","        super(SimpleRankModel, self).__init__()\n","        # GCN layers\n","        self.gcn1 = GCNLayer(input_size, gcn_hidden_size)\n","        self.gcn2 = GCNLayer(gcn_hidden_size, gcn_hidden_size)\n","        self.gcn3 = GCNLayer(gcn_hidden_size, gcn_hidden_size)\n","\n","        self.fc1 = nn.Linear(gcn_hidden_size, 128)\n","        self.relu = nn.ReLU()\n","        self.fc2 = nn.Linear(128, 64)\n","        self.fc3 = nn.Linear(64, 32)\n","        self.fc4 = nn.Linear(32, 2)\n","        self.sigmoid = nn.Sigmoid()\n","        self.dropout = nn.Dropout(p=dropout_prob)\n","        self.batch_norm1 = nn.BatchNorm1d(128)\n","        self.batch_norm2 = nn.BatchNorm1d(64)\n","        self.batch_norm3 = nn.BatchNorm1d(32)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        # GCN layers\n","        x = self.gcn1(x, edge_index)\n","        x = self.relu(x)\n","        x = self.gcn2(x, edge_index)\n","        x = self.relu(x)\n","\n","        # MLP layers\n","        x = self.batch_norm1(self.fc1(x))\n","        x = self.relu(x)\n","        x = self.dropout(x)\n","        x = self.batch_norm2(self.fc2(x))\n","        x = self.relu(x)\n","        x = self.dropout(x)\n","        x = self.batch_norm3(self.fc3(x))\n","        x = self.relu(x)\n","        x = self.fc4(x)\n","        return x\n","\n","def simple_ranking_loss(scores, labels):\n","    # Calculate pairwise differences only for positive pairs (labels == 1)\n","    pairwise_diff = scores[labels == 1].view(-1, 1) - scores[labels == 0].view(1, -1)\n","    return -torch.mean(nn.functional.logsigmoid(pairwise_diff))\n","\n","# Function to calculate accuracy\n","def calculate_accuracy(outputs, labels):\n","    predictions = outputs\n","    TP = ((predictions == 1) & (labels == 1)).sum().item()\n","    FP = ((predictions == 1) & (labels == 0)).sum().item()\n","    if TP + FP == 0:\n","        TPR = 1\n","    else:\n","        TPR = TP / (TP + FP)\n","    correct = (predictions == labels).sum().item()\n","    total = labels.size(0)\n","    accuracy = correct / total\n","    return accuracy, TPR\n","\n","\n","def train_model_simple(model, train_loader, val_loader, optimizer, criterion, batch_size, epochs=10):\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model.to(device)\n","    train_losses = []\n","    val_losses = []\n","    train_accuracies = []\n","    val_accuracies = []\n","    val_tprs = []\n","    train_tprs = []\n","    base_path = '/content/drive/MyDrive/Colab Notebooks/Decomp/Models/simplerank'\n","    for epoch in range(epochs):\n","        model.train()\n","        running_loss = 0.0\n","        start = 0\n","        train_epoch_loss = 0.0\n","        train_epoch_accuracy = 0.0\n","        train_epoch_tprs = 0.0\n","        total_length = len(train_loader) // batch_size\n","        for i in range(start, len(train_loader), batch_size):\n","            optimizer.zero_grad()\n","            scores = torch.empty(0, dtype=torch.float32, requires_grad=True).to(device)\n","            labels = torch.empty(0, dtype=torch.float32, requires_grad=True).to(device)\n","            for j in range(start, start + batch_size):\n","                if j >= len(train_loader):\n","                    break\n","                graph = train_loader[j]\n","                temp = model(graph)\n","                temp_softmax = F.softmax(temp, dim=1)\n","                temp2 = torch.argmax(temp_softmax, dim=1)\n","                scores = torch.cat([scores, temp2], dim=0)\n","                temp = graph.y\n","                labels = torch.cat([labels, temp], dim=0)\n","            start += batch_size\n","            scores = scores.squeeze().to(device)\n","            loss = criterion(scores, labels)\n","            train_epoch_loss += loss.item()\n","\n","            # Calculate accuracy\n","            accuracy,tpr = calculate_accuracy(scores, labels)\n","            train_epoch_tprs += tpr\n","            train_epoch_accuracy += accuracy\n","\n","            # Backward pass and optimization\n","            loss.backward()\n","            optimizer.step()\n","        train_tprs.append(train_epoch_tprs / total_length)\n","        average_train_loss = train_epoch_loss / total_length\n","        average_train_accuracy = train_epoch_accuracy / total_length\n","        train_losses.append(average_train_loss)\n","        train_accuracies.append(average_train_accuracy)\n","\n","        # Validation\n","        model.eval()\n","        val_epoch_loss = 0.0\n","        val_epoch_accuracy = 0.0\n","        val_epoch_tpr = 0.0\n","        test_length = len(val_loader) // batch_size\n","        with torch.no_grad():\n","            start = 0\n","            for i in range(start, len(val_loader), batch_size):\n","                graph.to(device)\n","                optimizer.zero_grad()\n","                scores = torch.empty(0, dtype=torch.float32, requires_grad=True).to(device)\n","                labels = torch.empty(0, dtype=torch.float32, requires_grad=True).to(device)\n","                for j in range(start, start + batch_size):\n","                    if j >= len(val_loader):\n","                        break\n","                    graph = val_loader[j]\n","                    temp = model(graph)\n","                    temp_softmax = F.softmax(temp, dim=1)\n","                    temp2 = torch.argmax(temp_softmax, dim=1)\n","                    scores = torch.cat([scores, temp2], dim=0)\n","                    labels = torch.cat([labels, graph.y], dim=0)\n","                start += batch_size\n","                scores = scores.squeeze().to(device)\n","                loss = criterion(scores, labels)\n","                val_epoch_loss += loss.item()\n","\n","                # Calculate accuracy\n","                accuracy, tpr = calculate_accuracy(scores, labels)\n","                val_epoch_accuracy += accuracy\n","                val_epoch_tpr += tpr\n","\n","\n","        val_tprs.append(val_epoch_tpr / test_length)\n","        average_val_loss = val_epoch_loss / test_length\n","        average_val_accuracy = val_epoch_accuracy / test_length\n","        val_losses.append(average_val_loss)\n","        val_accuracies.append(average_val_accuracy)\n","        save_path = f'{base_path}_{epoch+1}.pth'\n","        torch.save(model.state_dict(), save_path)\n","\n","        # Print progress\n","        print(f'Epoch [{epoch+1}/{epochs}], '\n","              f'Train Loss: {average_train_loss:.4f}, Train Acc: {average_train_accuracy:.4f}, '\n","              f'Train TPR: {train_epoch_tprs / total_length:.4f}, '\n","              f'Val Loss: {average_val_loss:.4f}, Val Acc: {average_val_accuracy:.4f}, '\n","              f'Val TPR: {val_epoch_tpr / test_length:.4f}')\n","    # Plot the training and validation loss curves\n","    plt.plot(range(1, epochs + 1), train_losses, label='Training Loss')\n","    plt.plot(range(1, epochs + 1), val_losses, label='Validation Loss')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n"],"metadata":{"id":"zwNrSsnu3Cl8"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["#  TRAIN SIMPLERANK"],"metadata":{"id":"fUXBZeX84AIs"}},{"cell_type":"code","source":["batch_size = 128\n","epochs = 50\n","input_size = 9\n","gcn_hidden_size = 256\n","simple_rank_model = SimpleRankModel(input_size, gcn_hidden_size)\n","criterion = simple_ranking_loss\n","optimizer = optim.Adam(simple_rank_model.parameters(), lr=0.01)\n","\n","train_model_simple(simple_rank_model, train_graphs, val_graphs, optimizer, criterion, batch_size=batch_size, epochs=epochs)"],"metadata":{"id":"9g7_PjQE55l6","colab":{"base_uri":"https://localhost:8080/","height":616},"executionInfo":{"status":"error","timestamp":1702407788727,"user_tz":300,"elapsed":188526,"user":{"displayName":"Jia He Sun","userId":"07783893916712904513"}},"outputId":"b5d3e970-01a1-4291-c14e-ae42d2a5506f"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch [1/50], Train Loss: 1.0063, Train Acc: 0.6260, Train TPR: 0.5589, Val Loss: 1.3876, Val Acc: 0.9700, Val TPR: 0.8911\n","Epoch [2/50], Train Loss: 1.0058, Train Acc: 0.6259, Train TPR: 0.5592, Val Loss: 1.3871, Val Acc: 0.9718, Val TPR: 0.8918\n","Epoch [3/50], Train Loss: 1.0063, Train Acc: 0.6258, Train TPR: 0.5589, Val Loss: 1.3885, Val Acc: 0.9681, Val TPR: 0.8901\n","Epoch [4/50], Train Loss: 1.0086, Train Acc: 0.6228, Train TPR: 0.5571, Val Loss: 1.3890, Val Acc: 0.9711, Val TPR: 0.8912\n","Epoch [5/50], Train Loss: 1.0046, Train Acc: 0.6263, Train TPR: 0.5599, Val Loss: 1.3902, Val Acc: 0.9748, Val TPR: 0.8923\n","Epoch [6/50], Train Loss: 1.0079, Train Acc: 0.6239, Train TPR: 0.5577, Val Loss: 1.4042, Val Acc: 0.9670, Val TPR: 0.8862\n","Epoch [7/50], Train Loss: 1.0058, Train Acc: 0.6255, Train TPR: 0.5591, Val Loss: 1.3931, Val Acc: 0.9720, Val TPR: 0.8906\n","Epoch [8/50], Train Loss: 1.0022, Train Acc: 0.6292, Train TPR: 0.5617, Val Loss: 1.3851, Val Acc: 0.9744, Val TPR: 0.8933\n","Epoch [9/50], Train Loss: 1.0076, Train Acc: 0.6243, Train TPR: 0.5579, Val Loss: 1.3830, Val Acc: 0.9693, Val TPR: 0.8918\n","Epoch [10/50], Train Loss: 1.0033, Train Acc: 0.6284, Train TPR: 0.5611, Val Loss: 1.3793, Val Acc: 0.9720, Val TPR: 0.8936\n","Epoch [11/50], Train Loss: 1.0061, Train Acc: 0.6252, Train TPR: 0.5588, Val Loss: 1.3834, Val Acc: 0.9724, Val TPR: 0.8929\n","Epoch [12/50], Train Loss: 1.0049, Train Acc: 0.6272, Train TPR: 0.5599, Val Loss: 1.3859, Val Acc: 0.9714, Val TPR: 0.8920\n","Epoch [13/50], Train Loss: 1.0038, Train Acc: 0.6275, Train TPR: 0.5606, Val Loss: 1.3801, Val Acc: 0.9694, Val TPR: 0.8925\n","Epoch [14/50], Train Loss: 1.0061, Train Acc: 0.6252, Train TPR: 0.5589, Val Loss: 1.3892, Val Acc: 0.9745, Val TPR: 0.8925\n","Epoch [15/50], Train Loss: 1.0070, Train Acc: 0.6239, Train TPR: 0.5582, Val Loss: 1.3901, Val Acc: 0.9689, Val TPR: 0.8901\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-15-bb5fc79c05dd>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_rank_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mtrain_model_simple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msimple_rank_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_graphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_graphs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-8-a191f5d046ba>\u001b[0m in \u001b[0;36mtrain_model_simple\u001b[0;34m(model, train_loader, val_loader, optimizer, criterion, batch_size, epochs)\u001b[0m\n\u001b[1;32m     84\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m                 \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                 \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0mtemp_softmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msoftmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mtemp2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtemp_softmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-8-a191f5d046ba>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;31m# GCN layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcn1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcn2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-5-21872637d934>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgcn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/conv/gcn_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    242\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0;31m# propagate_type: (x: Tensor, edge_weight: OptTensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 244\u001b[0;31m         out = self.propagate(edge_index, x=x, edge_weight=edge_weight,\n\u001b[0m\u001b[1;32m    245\u001b[0m                              size=None)\n\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, size, **kwargs)\u001b[0m\n\u001b[1;32m    478\u001b[0m                         \u001b[0maggr_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 480\u001b[0;31m                 \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maggregate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0maggr_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    481\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    482\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_aggregate_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/conv/message_passing.py\u001b[0m in \u001b[0;36maggregate\u001b[0;34m(self, inputs, index, ptr, dim_size)\u001b[0m\n\u001b[1;32m    602\u001b[0m         \u001b[0;32mas\u001b[0m \u001b[0mspecified\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mmeth\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0mby\u001b[0m \u001b[0mthe\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0maggr\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0margument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    603\u001b[0m         \"\"\"\n\u001b[0;32m--> 604\u001b[0;31m         return self.aggr_module(inputs, index, ptr=ptr, dim_size=dim_size,\n\u001b[0m\u001b[1;32m    605\u001b[0m                                 dim=self.node_dim)\n\u001b[1;32m    606\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/experimental.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_experimental_mode_enabled\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'disable_dynamic_shapes'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 115\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    116\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    117\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrequired_arg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrequired_args\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/aggr/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, index, ptr, dim_size, dim, **kwargs)\u001b[0m\n\u001b[1;32m    123\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 125\u001b[0;31m             return super().__call__(x, index=index, ptr=ptr, dim_size=dim_size,\n\u001b[0m\u001b[1;32m    126\u001b[0m                                     dim=dim, **kwargs)\n\u001b[1;32m    127\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mIndexError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1517\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1518\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1519\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1526\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1528\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1529\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/aggr/basic.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, index, ptr, dim_size, dim)\u001b[0m\n\u001b[1;32m     20\u001b[0m                 \u001b[0mptr\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m                 dim: int = -2) -> Tensor:\n\u001b[0;32m---> 22\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mptr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'sum'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/nn/aggr/base.py\u001b[0m in \u001b[0;36mreduce\u001b[0;34m(self, x, index, ptr, dim_size, dim, reduce)\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mscatter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    177\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m     def to_dense_batch(\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch_geometric/utils/scatter.py\u001b[0m in \u001b[0;36mscatter\u001b[0;34m(src, index, dim, dim_size, reduce)\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'sum'\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'add'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbroadcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnew_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscatter_add_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msrc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'mean'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"markdown","source":["#  Binary Class Model"],"metadata":{"id":"3XWy5_klyy6v"}},{"cell_type":"code","source":["class BinaryClassificationModel(nn.Module):\n","    def __init__(self, input_size, gcn_hidden_size, dropout_prob=0.3):\n","        super(BinaryClassificationModel, self).__init__()\n","        # GCN layers\n","        self.gcn1 = GCNLayer(input_size, gcn_hidden_size)\n","        self.gcn2 = GCNLayer(gcn_hidden_size, gcn_hidden_size)\n","        self.gcn3 = GCNLayer(gcn_hidden_size, gcn_hidden_size)\n","\n","        self.fc1 = nn.Linear(gcn_hidden_size, 128)\n","        self.relu = nn.ReLU()\n","        self.fc2 = nn.Linear(128, 64)\n","        self.fc3 = nn.Linear(64, 32)\n","        self.fc4 = nn.Linear(32, 2)\n","        self.sigmoid = nn.Sigmoid()\n","        self.dropout = nn.Dropout(p=dropout_prob)\n","        self.batch_norm1 = nn.BatchNorm1d(128)\n","        self.batch_norm2 = nn.BatchNorm1d(64)\n","        self.batch_norm3 = nn.BatchNorm1d(32)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        # GCN layers\n","        x = self.gcn1(x, edge_index)\n","        x = self.relu(x)\n","        x = self.gcn2(x, edge_index)\n","        x = self.relu(x)\n","\n","        # MLP layers\n","        x = self.batch_norm1(self.fc1(x))\n","        x = self.relu(x)\n","        x = self.dropout(x)\n","        x = self.batch_norm2(self.fc2(x))\n","        x = self.relu(x)\n","        x = self.dropout(x)\n","        x = self.batch_norm3(self.fc3(x))\n","        x = self.relu(x)\n","        x = self.fc4(x)\n","        return x\n","\n","\n","\n","def train_model_BC(model, train_loader, val_loader, optimizer, criterion, batch_size, epochs=10):\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model.to(device)\n","    train_losses = []\n","    val_losses = []\n","    train_accuracies = []\n","    val_accuracies = []\n","    val_tprs = []\n","    train_tprs = []\n","    base_path = '/content/drive/MyDrive/Colab Notebooks/Decomp/Models/BC'\n","    for epoch in range(epochs):\n","        model.train()\n","        running_loss = 0.0\n","        start = 0\n","        train_epoch_loss = 0.0\n","        train_epoch_accuracy = 0.0\n","        train_epoch_tprs = 0.0\n","        total_length = len(train_loader) // batch_size\n","        for i in range(start, len(train_loader), batch_size):\n","            optimizer.zero_grad()\n","            scores = torch.empty(0, dtype=torch.float32, requires_grad=True).to(device)\n","            labels = torch.empty(0, dtype=torch.float32, requires_grad=True).to(device)\n","            for j in range(start, start + batch_size):\n","                if j >= len(train_loader):\n","                    break\n","                graph = train_loader[j]\n","                temp = model(graph)\n","                temp_softmax = F.softmax(temp, dim=1)\n","                temp2 = torch.argmax(temp_softmax, dim=1)\n","                scores = torch.cat([scores, temp2], dim=0)\n","                temp = graph.y\n","                labels = torch.cat([labels, temp], dim=0)\n","            start += batch_size\n","            scores = scores.squeeze().to(device)\n","            loss = criterion(scores, labels)\n","            train_epoch_loss += loss.item()\n","\n","            # Calculate accuracy\n","            accuracy,tpr = calculate_accuracy(scores, labels)\n","            train_epoch_tprs += tpr\n","            train_epoch_accuracy += accuracy\n","\n","            # Backward pass and optimization\n","            loss.backward()\n","            optimizer.step()\n","        train_tprs.append(train_epoch_tprs / total_length)\n","        average_train_loss = train_epoch_loss / total_length\n","        average_train_accuracy = train_epoch_accuracy / total_length\n","        train_losses.append(average_train_loss)\n","        train_accuracies.append(average_train_accuracy)\n","\n","        # Validation\n","        model.eval()\n","        val_epoch_loss = 0.0\n","        val_epoch_accuracy = 0.0\n","        val_epoch_tpr = 0.0\n","        test_length = len(val_loader) // batch_size\n","        with torch.no_grad():\n","            start = 0\n","            for i in range(start, len(val_loader), batch_size):\n","                graph.to(device)\n","                optimizer.zero_grad()\n","                scores = torch.empty(0, dtype=torch.float32, requires_grad=True).to(device)\n","                labels = torch.empty(0, dtype=torch.float32, requires_grad=True).to(device)\n","                for j in range(start, start + batch_size):\n","                    if j >= len(val_loader):\n","                        break\n","                    graph = val_loader[j]\n","                    temp = model(graph)\n","                    temp_softmax = F.softmax(temp, dim=1)\n","                    temp2 = torch.argmax(temp_softmax, dim=1)\n","                    scores = torch.cat([scores, temp2], dim=0)\n","                    labels = torch.cat([labels, graph.y], dim=0)\n","                start += batch_size\n","                scores = scores.squeeze().to(device)\n","                loss = criterion(scores, labels)\n","                val_epoch_loss += loss.item()\n","\n","                # Calculate accuracy\n","                accuracy, tpr = calculate_accuracy(scores, labels)\n","                val_epoch_accuracy += accuracy\n","                val_epoch_tpr += tpr\n","\n","\n","        val_tprs.append(val_epoch_tpr / test_length)\n","        average_val_loss = val_epoch_loss / test_length\n","        average_val_accuracy = val_epoch_accuracy / test_length\n","        val_losses.append(average_val_loss)\n","        val_accuracies.append(average_val_accuracy)\n","        save_path = f'{base_path}_{epoch+1}.pth'\n","        torch.save(model.state_dict(), save_path)\n","\n","        # Print progress\n","        print(f'Epoch [{epoch+1}/{epochs}], '\n","              f'Train Loss: {average_train_loss:.4f}, Train Acc: {average_train_accuracy:.4f}, '\n","              f'Train TPR: {train_epoch_tprs / total_length:.4f}, '\n","              f'Val Loss: {average_val_loss:.4f}, Val Acc: {average_val_accuracy:.4f}, '\n","              f'Val TPR: {val_epoch_tpr / test_length:.4f}')\n","    # Plot the training and validation loss curves\n","    plt.plot(range(1, epochs + 1), train_losses, label='Training Loss')\n","    plt.plot(range(1, epochs + 1), val_losses, label='Validation Loss')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()\n","\n","class FocalLoss(nn.Module):\n","    def __init__(self, alpha=0.9, gamma=2, logits=True, reduce=True):\n","        super(FocalLoss, self).__init__()\n","        self.alpha = alpha\n","        self.gamma = gamma\n","        self.logits = logits\n","        self.reduce = reduce\n","\n","    def forward(self, inputs, targets):\n","        if self.logits:\n","            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n","        else:\n","            BCE_loss = F.binary_cross_entropy(inputs, targets, reduction='none')\n","\n","        pt = torch.exp(-BCE_loss)\n","        focal_loss = self.alpha * (1 - pt) ** self.gamma * BCE_loss\n","\n","        if self.reduce:\n","            return torch.mean(focal_loss)\n","        else:\n","            return focal_loss\n"],"metadata":{"id":"qHGoHKTP1pCZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 2\n","epochs = 50\n","input_size = 9\n","gcn_hidden_size = 256\n","BC_model = BinaryClassificationModel(input_size, gcn_hidden_size)\n","criterion = FocalLoss(alpha=1, gamma=5)\n","optimizer = optim.Adam(BC_model.parameters(), lr=0.005)\n","\n","train_model_BC(BC_model, train_graphs, val_graphs, optimizer, criterion, batch_size=batch_size, epochs=epochs)"],"metadata":{"id":"aoux4njczEcp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# PairwiseRank"],"metadata":{"id":"vJK0gPojy61I"}},{"cell_type":"code","source":["class PairwiseRankModel(nn.Module):\n","    def __init__(self, input_size, gcn_hidden_size, dropout_prob=0.3):\n","        super(PairwiseRankModel, self).__init__()\n","        # GCN layers\n","        self.gcn1 = GCNLayer(input_size, gcn_hidden_size)\n","        self.gcn2 = GCNLayer(gcn_hidden_size, gcn_hidden_size)\n","        self.gcn3 = GCNLayer(gcn_hidden_size, gcn_hidden_size)\n","\n","        self.fc1 = nn.Linear(gcn_hidden_size, 128)\n","        self.relu = nn.ReLU()\n","        self.fc2 = nn.Linear(128, 64)\n","        self.fc3 = nn.Linear(64, 32)\n","        self.fc4 = nn.Linear(32, 2)\n","        self.sigmoid = nn.Sigmoid()\n","        self.dropout = nn.Dropout(p=dropout_prob)\n","        self.batch_norm1 = nn.BatchNorm1d(128)\n","        self.batch_norm2 = nn.BatchNorm1d(64)\n","        self.batch_norm3 = nn.BatchNorm1d(32)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        # GCN layers\n","        x = self.gcn1(x, edge_index)\n","        x = self.relu(x)\n","        x = self.gcn2(x, edge_index)\n","        x = self.relu(x)\n","\n","        # MLP layers\n","        x = self.batch_norm1(self.fc1(x))\n","        x = self.relu(x)\n","        x = self.dropout(x)\n","        x = self.batch_norm2(self.fc2(x))\n","        x = self.relu(x)\n","        x = self.dropout(x)\n","        x = self.batch_norm3(self.fc3(x))\n","        x = self.relu(x)\n","        x = self.fc4(x)\n","        return x\n","\n","\n","def train_model_pairwise(model, train_loader, val_loader, optimizer, criterion, batch_size, epochs=10):\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model.to(device)\n","    criterion = criterion.to(device)\n","    train_losses = []\n","    val_losses = []\n","    val_accuracies = []\n","    #base_path = '/content/drive/MyDrive/Colab Notebooks/Decomp/Models/PairwiseRank'\n","    for epoch in range(epochs):\n","        model.train()\n","        running_loss = 0.0\n","        start = 0\n","        for i in range(start, len(train_loader), batch_size):\n","            optimizer.zero_grad()\n","            scores = torch.empty(0, dtype=torch.float32, requires_grad=True).to(device)\n","            labels = torch.empty(0, dtype=torch.float32, requires_grad=True).to(device)\n","            for j in range(start, start + batch_size):\n","                if j >= len(train_loader):\n","                    break\n","                graph = train_loader[j]\n","                temp = model(graph)\n","                temp_softmax = F.softmax(temp, dim=1)\n","                temp2 = torch.argmax(temp_softmax, dim=1)\n","                scores = torch.cat([scores, temp2], dim=0)\n","                temp = graph.y.to(device)\n","                labels = torch.cat([labels, temp], dim=0)\n","            start += batch_size\n","            # Create all possible pairs\n","            pairs_list = list(combinations(range(len(scores)), 2))\n","            # Calculate pairwise scores\n","            loss = 0\n","            pairwise_labels = torch.empty(0, dtype=torch.float32, requires_grad=True)\n","            pairwise_scores_list = []\n","            for pairs in pairs_list:\n","                if labels[pairs[0]] > labels[pairs[1]]:\n","                    pairwise_label = 1\n","                elif labels[pairs[0]] < labels[pairs[1]]:\n","                    pairwise_label = -1\n","                else:\n","                    pairwise_label = 0\n","                pairwise_scores_list.append([scores[pairs[0]], scores[pairs[1]]])\n","                pairwise_labels = torch.cat((pairwise_labels, torch.tensor([pairwise_label])))\n","            pairwise_labels = pairwise_labels.to(device)\n","            pairwise_scores = torch.tensor(pairwise_scores_list, dtype=torch.float32, requires_grad=True).to(device)\n","            print(pairwise_scores)\n","            loss = criterion(pairwise_scores[:, 0], pairwise_scores[:, 1], pairwise_labels)\n","            loss.backward()\n","            optimizer.step()\n","            running_loss += loss.item()\n","\n","        average_loss = running_loss / len(train_loader)\n","        train_losses.append(average_loss)\n","        print(f\"Epoch {epoch + 1}/{epochs}, Training Loss: {average_loss}\")\n","\n","    # Plot the training and validation loss curves\n","    plt.plot(range(1, epochs + 1), train_losses, label='Training Loss')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()"],"metadata":{"id":"piuNHjshy6dH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# REGRESSION"],"metadata":{"id":"n9m2gUDAKj5O"}},{"cell_type":"code","source":["class RegressionModel(nn.Module):\n","    def __init__(self, input_size, gcn_hidden_size, dropout_prob=0.3):\n","        super(RegressionModel, self).__init__()\n","        # GCN layers\n","        self.gcn1 = GCNLayer(input_size, gcn_hidden_size)\n","        self.gcn2 = GCNLayer(gcn_hidden_size, gcn_hidden_size)\n","        self.gcn3 = GCNLayer(gcn_hidden_size, gcn_hidden_size)\n","\n","        self.fc1 = nn.Linear(gcn_hidden_size, 128)\n","        self.relu = nn.ReLU()\n","        self.fc2 = nn.Linear(128, 64)\n","        self.fc3 = nn.Linear(64, 32)\n","        self.fc4 = nn.Linear(32, 1)\n","        self.sigmoid = nn.Sigmoid()\n","        self.dropout = nn.Dropout(p=dropout_prob)\n","        self.batch_norm1 = nn.BatchNorm1d(128)\n","        self.batch_norm2 = nn.BatchNorm1d(64)\n","        self.batch_norm3 = nn.BatchNorm1d(32)\n","\n","    def forward(self, data):\n","        x, edge_index = data.x, data.edge_index\n","        x = self.gcn1(x, edge_index)\n","        x = self.relu(x)\n","        x = self.gcn2(x, edge_index)\n","        x = self.relu(x)\n","\n","        # MLP layers\n","        x = self.batch_norm1(self.fc1(x))\n","        x = self.relu(x)\n","        x = self.dropout(x)\n","        x = self.batch_norm2(self.fc2(x))\n","        x = self.relu(x)\n","        x = self.dropout(x)\n","        x = self.batch_norm3(self.fc3(x))\n","        x = self.relu(x)\n","        x = self.fc4(x)\n","        x = self.sigmoid(x)\n","        return x\n","\n","\n","def train_model_regression(model, train_loader, val_loader, optimizer, criterion, batch_size, patience, epochs=10):\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model.to(device)\n","    train_losses = []\n","    val_losses = []\n","    base_path = '/content/drive/MyDrive/Colab Notebooks/Decomp/Models/regression'\n","    best_train_loss = float('inf')\n","    consecutive_no_improvement = 0\n","    for epoch in range(epochs):\n","        model.train()\n","        running_loss = 0.0\n","        start = 0\n","        train_epoch_loss = 0.0\n","        total_length = len(train_loader) // batch_size\n","\n","\n","        for i in range(start, len(train_loader), batch_size):\n","            optimizer.zero_grad()\n","            scores = torch.empty(0, dtype=torch.float32, requires_grad=True).to(device)\n","            labels = torch.empty(0, dtype=torch.float32, requires_grad=True).to(device)\n","            for j in range(start, start + batch_size):\n","                if j >= len(train_loader):\n","                    break\n","                graph = train_loader[j]\n","                temp = model(graph)\n","                scores = torch.cat([scores, temp], dim=0)\n","                temp = graph.y\n","                temp = temp.to(device)\n","                labels = torch.cat([labels, temp], dim=0)\n","            start += batch_size\n","            scores = scores.squeeze().to(device)\n","            loss = criterion(scores, labels)\n","            train_epoch_loss += loss.item()\n","\n","\n","            # Backward pass and optimization\n","            loss.backward()\n","            optimizer.step()\n","\n","        average_train_loss = train_epoch_loss / total_length\n","        train_losses.append(average_train_loss)\n","\n","\n","        # Print progress\n","        print(f'Epoch [{epoch+1}/{epochs}], '\n","              f'Train Loss: {average_train_loss:.4f}')\n","        if train_losses:\n","            if min(train_losses) < best_train_loss:\n","                best_train_loss = min(train_losses)\n","                consecutive_no_improvement = 0\n","            else:\n","                consecutive_no_improvement += 1\n","            if consecutive_no_improvement >= patience:\n","                print(f'Early stopping at epoch {epoch+1} due to no improvement in training loss.')\n","                break\n","    # Plot the training and validation loss curves\n","    plt.plot(range(1, epoch+2), train_losses, label='Training Loss')\n","    plt.xlabel('Epoch')\n","    plt.ylabel('Loss')\n","    plt.legend()\n","    plt.show()"],"metadata":{"id":"affeIXQUKZ5b"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# IMITATION EVALUATION"],"metadata":{"id":"lVgKGa1pDo5h"}},{"cell_type":"code","source":["# function to evaluate imitation algo GCN VERSION\n","def model_imitation_evaluation(model, pygraph):\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model.to(device)\n","    model.eval()\n","    nxgraph = to_networkx(pygraph)\n","    best_node = None\n","    best_value = -9999\n","    normalize_function = max_normalize # [0,1] continuous\n","    normalize_param = 0.2\n","    dataset_normalize([pygraph], normalize_function=normalize_function, normalize_param=normalize_param)\n","    labels = pygraph.y\n","    outputs = model(pygraph)\n","    outputs = F.softmax(outputs, dim=1)\n","    temp = outputs.detach().cpu()\n","    temp = temp.numpy()\n","    outputs = temp[:, 1]\n","    best_value = -9999\n","    best_node = None\n","    for node, output_value in enumerate(outputs):\n","        #print(node)\n","        if output_value > best_value:\n","            best_value = output_value\n","            best_node = node\n","    output_label = labels[best_node]\n","    return output_label"],"metadata":{"id":"zNuIfD0mDqQx"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# function to evaluate imitation algo GCN VERSION\n","def model_imitation_evaluation_pairwise(model, pygraph):\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model.to(device)\n","    pygraph.to(device)\n","    # save labels for eval\n","    normalize_function = max_normalize # [0,1] continuous\n","    normalize_param = 0.2\n","    dataset_normalize([pygraph], normalize_function=normalize_function, normalize_param=normalize_param)\n","    labels = pygraph.y\n","    # completely normalize now\n","    normalize_function = max_normalize_binary # [0,1] continuous\n","    normalize_param = 0.5\n","    dataset_normalize([pygraph], normalize_function=normalize_function, normalize_param=normalize_param)\n","    batch_size = 1\n","    epochs = 15\n","    input_size = 9\n","    gcn_hidden_size = 256\n","    criterion = nn.MarginRankingLoss(reduction='sum')\n","    optimizer = optim.Adam(model.parameters(), lr=0.005)\n","    # Train the model with validation\n","    train_model_pairwise(model, [pygraph], val_graphs, optimizer, criterion, batch_size=batch_size, epochs=epochs)\n","    model.eval()\n","    nxgraph = to_networkx(pygraph)\n","    best_node = None\n","    best_value = -9999\n","    outputs = model(pygraph)\n","    outputs = F.softmax(outputs, dim=1)\n","    temp = outputs.detach().cpu()\n","    temp = temp.numpy()\n","    outputs = temp[:, 1]\n","    best_value = -9999\n","    best_node = None\n","    for node, output_value in enumerate(outputs):\n","        #print(node)\n","        if output_value > best_value:\n","            best_value = output_value\n","            best_node = node\n","    output_label = labels[best_node]\n","    return output_label"],"metadata":{"id":"KrRPI3AbKf1L"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# function to evaluate imitation algo GCN VERSION\n","def model_imitation_evaluation_regression(model, pygraph):\n","    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n","    model.to(device)\n","    pygraph.to(device)\n","    # save labels for eval\n","    normalize_function = max_normalize # [0,1] continuous\n","    normalize_param = 0.2\n","    dataset_normalize([pygraph], normalize_function=normalize_function, normalize_param=normalize_param)\n","    labels = pygraph.y\n","    batch_size = 1\n","    epochs = 2000\n","    input_size = 9\n","    gcn_hidden_size = 256\n","    patience = 100\n","    criterion = nn.MSELoss()\n","    optimizer = optim.Adam(model.parameters(), lr=0.0001 )\n","    # Train the model with validation\n","    train_model_regression(model, [pygraph], val_graphs, optimizer, criterion, batch_size=batch_size, patience=patience, epochs=epochs)\n","    model.eval()\n","    nxgraph = to_networkx(pygraph)\n","    best_node = None\n","    best_value = -9999\n","    outputs = model(pygraph)\n","    outputs = outputs.detach().cpu()\n","    outputs = outputs.numpy()\n","    best_value = -9999\n","    best_node = None\n","    for node, output_value in enumerate(outputs):\n","        #print(node)\n","        if output_value > best_value:\n","            best_value = output_value\n","            best_node = node\n","    output_label = labels[best_node]\n","    return output_label"],"metadata":{"id":"nKtBKzx1LwF-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import matplotlib.pyplot as plt\n","from torch.utils.data import Subset, random_split\n","import numpy as np\n","\n","# Load data and normalize the labels\n","loaded_dataset = torch.load('/content/drive/MyDrive/Colab Notebooks/Decomp/LabeledData/NetworkxGraphs/test_200nodes_100graphs_features.pt')"],"metadata":{"id":"GM3mMSOTDrEc"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["test_size = len(loaded_dataset)\n","bc_outputs = []\n","simple_rank_outputs = []\n","simple_rank_instance_outputs = []\n","pairwise_rank_instance_outputs = []\n","regression_instance_outputs = []\n","for i in tqdm(range(test_size)):\n","    print(\"GRAPH NUMBER:\", i)\n","    graph = loaded_dataset[i]\n","    #bc_model = BinaryClassificationModel(9, 256)\n","    #bc_model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/Decomp/Models/Accepted/BC_16.pth', map_location=torch.device('cpu')))\n","    simple_rank_model = SimpleRankModel(9, 256)\n","    simple_rank_model.load_state_dict(torch.load('/content/drive/MyDrive/Colab Notebooks/Decomp/Models/Accepted/pairwiserank_14.pth', map_location=torch.device('cpu')))\n","    #pairwise_rank_model_instance = PairwiseRankModel(9, 256)\n","    #regression_model_instance = RegressionModel(9, 256)\n","    #bc_output = model_imitation_evaluation(bc_model, graph)\n","    simple_rank_output = model_imitation_evaluation(simple_rank_model, graph)\n","    #pairwise_rank_instance_output = model_imitation_evaluation_pairwise(pairwise_rank_model_instance, graph)\n","    #regression_output = model_imitation_evaluation_regression(regression_model_instance, graph)\n","    # save\n","    #bc_outputs.append(bc_output.item())\n","    simple_rank_outputs.append(simple_rank_output.item())\n","    #pairwise_rank_instance_outputs.append(pairwise_rank_instance_output.item())\n","    #regression_instance_outputs.append(regression_output.item())\n","\n","print('\\n')\n","print(bc_outputs)\n","print(simple_rank_outputs)\n","print(pairwise_rank_instance_outputs)\n","print(regression_instance_outputs)\n","\n","print(np.mean(bc_outputs))\n","print(np.mean(simple_rank_outputs))\n","print(np.mean(pairwise_rank_instance_outputs))\n","print(np.mean(regression_instance_outputs))"],"metadata":{"id":"lDXcxVPKDxyC"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["bc_outputs = [0.7795275449752808, 0.8662420511245728, 0.8314606547355652, 1.0, 0.9417475461959839, 0.8320610523223877, 1.0, 0.013333333656191826, 0.019999999552965164, 0.8529411554336548, 0.7394366264343262, 0.7822580933570862, 1.0, 1.0, 0.7142857313156128, 0.8819444179534912, 0.7808219194412231, 0.0139860138297081, 0.7241379022598267, 0.013793103396892548, 0.8306451439857483, 1.0, 0.8644067645072937, 0.8880000114440918, 0.8164557218551636, 0.7405063509941101, 0.774193525314331, 0.8518518805503845, 0.7956204414367676, 0.012658228166401386, 0.8598726391792297, 0.014492753893136978, 0.904347836971283, 0.23333333432674408, 1.0, 0.5714285969734192, 1.0, 0.7553191781044006, 0.8300653696060181, 0.8203125, 0.7594936490058899, 1.0, 0.7640449404716492, 1.0, 0.01652892492711544, 0.7300000190734863, 1.0, 0.834782600402832, 0.8376068472862244, 1.0, 0.8113207817077637, 0.8229166865348816, 0.7816091775894165, 0.012820512987673283, 0.9541984796524048, 0.7654321193695068, 0.7888888716697693, 1.0, 0.841269850730896, 0.7472527623176575, 0.7572815418243408, 0.5833333134651184, 0.01315789483487606, 0.8217821717262268, 0.7586206793785095, 0.8558558821678162, 0.7945205569267273, 0.4000000059604645, 0.5, 0.012500000186264515, 0.8695651888847351, 0.8928571343421936, 0.013071895577013493, 1.0, 0.7254902124404907, 0.6893203854560852, 1.0, 0.8041236996650696, 1.0, 0.8661417365074158, 1.0, 0.8243243098258972, 0.8099173307418823, 0.9767441749572754, 1.0, 0.7868852615356445, 0.8272727131843567, 0.8692810535430908, 1.0, 0.013333333656191826, 1.0, 0.014492753893136978, 0.6516854166984558, 0.747474730014801, 0.834645688533783, 0.7964601516723633, 0.9509803652763367, 0.8214285969734192, 0.8559321761131287, 1.0]\n","simple_rank_outputs = [0.7244094610214233, 0.7324841022491455, 0.7415730357170105, 1.0, 0.7572815418243408, 0.8396946787834167, 1.0, 0.8600000143051147, 0.02500000037252903, 0.8235294222831726, 0.8380281925201416, 0.8064516186714172, 0.14499999582767487, 1.0, 0.8067227005958557, 0.8680555820465088, 0.8630136847496033, 0.8741258978843689, 0.7931034564971924, 0.013793103396892548, 0.7903226017951965, 1.0, 0.7627118825912476, 0.8960000276565552, 0.8481012582778931, 0.7594936490058899, 0.8387096524238586, 0.7222222089767456, 0.7299270033836365, 0.7848101258277893, 0.7898089289665222, 1.0, 0.8086956739425659, 0.03333333507180214, 1.0, 0.0714285746216774, 1.0, 0.7340425252914429, 0.8235294222831726, 0.875, 0.7721518874168396, 0.009999999776482582, 0.6853932738304138, 0.004999999888241291, 1.0, 0.8500000238418579, 1.0, 0.8782608509063721, 0.7606837749481201, 0.014999999664723873, 0.7735849022865295, 0.7916666865348816, 0.6551724076271057, 0.012820512987673283, 0.7633587718009949, 0.7777777910232544, 0.855555534362793, 1.0, 0.7777777910232544, 0.8241758346557617, 0.7961165308952332, 0.0833333358168602, 0.01315789483487606, 0.8712871074676514, 0.8390804529190063, 0.8198198080062866, 0.8630136847496033, 0.4000000059604645, 0.1666666716337204, 0.012500000186264515, 0.8695651888847351, 0.8095238208770752, 0.7843137383460999, 1.0, 0.7941176295280457, 0.708737850189209, 1.0, 0.6907216310501099, 1.0, 0.8897637724876404, 1.0, 0.837837815284729, 0.8181818127632141, 0.9224806427955627, 1.0, 0.8032786846160889, 0.800000011920929, 0.8039215803146362, 1.0, 0.8866666555404663, 1.0, 0.9637681245803833, 0.8202247023582458, 0.808080792427063, 0.9212598204612732, 0.8761062026023865, 0.7450980544090271, 0.7976190447807312, 0.8644067645072937, 1.0]\n","regression_outputs = [0.7952755689620972, 0.8152866363525391, 0.6966292262077332, 1.0, 0.7766990065574646, 0.847328245639801, 1.0, 0.9133333563804626, 0.02500000037252903, 0.656862735748291, 0.8239436745643616, 0.9112903475761414, 0.14499999582767487, 1.0, 0.9159663915634155, 0.013888888992369175, 0.7739726305007935, 0.0139860138297081, 0.9425287246704102, 0.013793103396892548, 0.9435483813285828, 1.0, 0.7627118825912476, 0.8799999952316284, 0.012658228166401386, 0.7784810066223145, 0.7311828136444092, 0.7129629850387573, 0.8321167826652527, 0.8860759735107422, 0.012738853693008423, 0.014492753893136978, 0.678260862827301, 0.03333333507180214, 1.0, 0.0714285746216774, 1.0, 0.7127659320831299, 0.843137264251709, 0.7890625, 0.8101266026496887, 0.009999999776482582, 0.7977527976036072, 0.004999999888241291, 0.01652892492711544, 0.7699999809265137, 1.0, 0.6695652008056641, 0.7606837749481201, 0.014999999664723873, 0.805031418800354, 0.84375, 0.931034505367279, 0.012820512987673283, 0.8549618124961853, 0.8765432238578796, 0.7222222089767456, 1.0, 0.8730158805847168, 0.6813187003135681, 1.0, 0.0833333358168602, 0.01315789483487606, 0.7623762488365173, 0.7701149582862854, 0.684684693813324, 0.8287671208381653, 0.20000000298023224, 0.1666666716337204, 0.012500000186264515, 0.739130437374115, 0.7857142686843872, 0.013071895577013493, 1.0, 0.7352941036224365, 0.6699029207229614, 1.0, 0.6391752362251282, 1.0, 0.8267716765403748, 1.0, 0.8716216087341309, 0.702479362487793, 0.8682170510292053, 1.0, 0.7950819730758667, 0.7454545497894287, 0.7516340017318726, 1.0, 0.800000011920929, 1.0, 0.014492753893136978, 0.7865168452262878, 0.6868686676025391, 0.7165354490280151, 0.6637167930603027, 0.8235294222831726, 0.8690476417541504, 0.6779661178588867, 1.0]\n","pairwise_rank_outputs = [0.7637795209884644, 0.7643312215805054, 0.7528089880943298, 1.0, 0.8834951519966125, 0.7557252049446106, 1.0, 0.013333333656191826, 1.0, 0.8235294222831726, 0.6971830725669861, 0.7983871102333069, 1.0, 1.0, 0.7815126180648804, 0.013888888992369175, 0.7397260069847107, 0.0139860138297081, 0.7701149582862854, 0.013793103396892548, 0.6693548560142517, 1.0, 0.8644067645072937, 0.7919999957084656, 0.012658228166401386, 0.6645569801330566, 0.774193525314331, 0.8333333134651184, 0.8029196858406067, 0.012658228166401386, 0.7579618096351624, 0.014492753893136978, 0.782608687877655, 0.2666666805744171, 1.0, 0.6428571343421936, 1.0, 0.7978723645210266, 0.7450980544090271, 0.78125, 0.753164529800415, 1.0, 0.7191011309623718, 1.0, 0.01652892492711544, 0.8500000238418579, 1.0, 0.7652173638343811, 0.7435897588729858, 1.0, 0.805031418800354, 0.84375, 0.7356321811676025, 0.012820512987673283, 0.7099236845970154, 0.8518518805503845, 0.7333333492279053, 1.0, 0.7698412537574768, 0.8461538553237915, 0.7766990065574646, 0.3333333432674408, 0.01315789483487606, 0.8613861203193665, 0.7931034564971924, 0.7207207083702087, 0.7602739930152893, 0.4000000059604645, 0.5, 0.012500000186264515, 0.7739130258560181, 0.8928571343421936, 0.758169949054718, 1.0, 0.8627451062202454, 0.8834951519966125, 1.0, 0.8556700944900513, 1.0, 0.6929134130477905, 1.0, 0.8040540814399719, 0.7933884263038635, 0.7054263353347778, 1.0, 0.7131147384643555, 0.7909091114997864, 0.013071895577013493, 1.0, 0.8199999928474426, 1.0, 0.014492753893136978, 0.6741573214530945, 0.868686854839325, 0.9055117964744568, 0.7876105904579163, 0.8921568393707275, 0.8095238208770752, 0.8389830589294434, 1.0]\n","pairwise_rank_instance_outputs = [0.7716535329818726, 0.7643312215805054, 0.8426966071128845, 1.0, 0.7766990065574646, 0.7557252049446106, 1.0, 0.9599999785423279, 1.0, 0.656862735748291, 0.8521126508712769, 0.725806474685669, 1.0, 1.0, 0.7815126180648804, 0.9166666865348816, 0.8082191944122314, 1.0, 0.7586206793785095, 0.013793103396892548, 0.6693548560142517, 1.0, 0.805084764957428, 0.8159999847412109, 0.012658228166401386, 0.8417721390724182, 0.8817204236984253, 0.8888888955116272, 0.8029196858406067, 0.012658228166401386, 0.8025477528572083, 0.014492753893136978, 0.7739130258560181, 0.2666666805744171, 1.0, 0.5714285969734192, 1.0, 0.7553191781044006, 0.7450980544090271, 0.890625, 0.8481012582778931, 1.0, 0.6966292262077332, 1.0, 0.01652892492711544, 0.8700000047683716, 1.0, 0.8782608509063721, 0.7606837749481201, 1.0, 0.805031418800354, 0.8020833134651184, 0.8390804529190063, 0.012820512987673283, 0.7404580116271973, 0.8518518805503845, 0.9555555582046509, 1.0, 0.738095223903656, 0.7692307829856873, 0.7572815418243408, 0.3333333432674408, 0.01315789483487606, 0.7029703259468079, 0.7701149582862854, 0.8558558821678162, 1.0, 0.6000000238418579, 0.5, 0.012500000186264515, 0.739130437374115, 0.988095223903656, 0.758169949054718, 1.0, 0.7843137383460999, 0.6699029207229614, 1.0, 0.8865979313850403, 1.0, 0.6929134130477905, 1.0, 0.7432432174682617, 0.702479362487793, 0.7054263353347778, 1.0, 0.7950819730758667, 0.7727272510528564, 0.8888888955116272, 1.0, 0.8199999928474426, 1.0, 0.9637681245803833, 0.6292135119438171, 0.6868686676025391, 0.834645688533783, 0.6637167930603027, 0.7450980544090271, 0.9642857313156128, 0.8305084705352783, 1.0]\n","regression_instance_outputs = [0.7795275449752808, 0.012738853693008423, 0.7865168452262878, 1.0, 0.8834951519966125, 0.8320610523223877, 1.0, 0.013333333656191826, 1.0, 0.8921568393707275, 1.0, 0.8145161271095276, 1.0, 1.0, 0.9495798349380493, 0.9166666865348816, 0.7534246444702148, 0.9510489702224731, 0.7471264600753784, 0.9379310607910156, 0.8387096524238586, 1.0, 0.7966101765632629, 0.8880000114440918, 0.9367088675498962, 0.7911392450332642, 1.0, 0.8148148059844971, 0.9416058659553528, 0.905063271522522, 0.012738853693008423, 1.0, 0.843478262424469, 0.3333333432674408, 1.0, 0.6428571343421936, 1.0, 0.8829787373542786, 0.7450980544090271, 0.9609375, 0.753164529800415, 1.0, 0.7528089880943298, 1.0, 1.0, 0.8999999761581421, 1.0, 0.895652174949646, 0.8461538553237915, 1.0, 0.805031418800354, 1.0, 0.6781609058380127, 1.0, 0.9160305261611938, 0.7407407164573669, 0.9444444179534912, 1.0, 0.9047619104385376, 0.9340659379959106, 0.7864077687263489, 0.3333333432674408, 0.01315789483487606, 0.7623762488365173, 0.8735632300376892, 0.7387387156486511, 0.8287671208381653, 0.4000000059604645, 0.5, 0.012500000186264515, 0.8695651888847351, 0.7976190447807312, 0.9411764740943909, 1.0, 0.8529411554336548, 0.708737850189209, 1.0, 0.7835051417350769, 1.0, 0.8503937125205994, 1.0, 0.8243243098258972, 0.93388432264328, 0.8914728760719299, 1.0, 0.9180327653884888, 0.8272727131843567, 0.8888888955116272, 1.0, 0.8866666555404663, 1.0, 0.9637681245803833, 0.8426966071128845, 0.7979797720909119, 0.9055117964744568, 0.9469026327133179, 0.8039215803146362, 0.7976190447807312, 0.7711864113807678, 1.0]\n","\n","\n","\n","#0.72958134002983577 bc\n","#0.7406943323463202 simple rank\n","#0.6593492193240672 regression\n","#0.7127844956889748 pairwise\n","#0.7633054879307747 pairwise instance\n","#0.8272812394890934 regression instance"],"metadata":{"id":"2x1yYY8BF578","executionInfo":{"status":"ok","timestamp":1703028145978,"user_tz":480,"elapsed":296,"user":{"displayName":"Jia He Sun","userId":"07783893916712904513"}}},"execution_count":1,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","bc_outputs = [0.7795275449752808, 0.8662420511245728, 0.8314606547355652, 1.0, 0.9417475461959839, 0.8320610523223877, 1.0, 0.013333333656191826, 0.019999999552965164, 0.8529411554336548, 0.7394366264343262, 0.7822580933570862, 1.0, 1.0, 0.7142857313156128, 0.8819444179534912, 0.7808219194412231, 0.0139860138297081, 0.7241379022598267, 0.013793103396892548, 0.8306451439857483, 1.0, 0.8644067645072937, 0.8880000114440918, 0.8164557218551636, 0.7405063509941101, 0.774193525314331, 0.8518518805503845, 0.7956204414367676, 0.012658228166401386, 0.8598726391792297, 0.014492753893136978, 0.904347836971283, 0.23333333432674408, 1.0, 0.5714285969734192, 1.0, 0.7553191781044006, 0.8300653696060181, 0.8203125, 0.7594936490058899, 1.0, 0.7640449404716492, 1.0, 0.01652892492711544, 0.7300000190734863, 1.0, 0.834782600402832, 0.8376068472862244, 1.0, 0.8113207817077637, 0.8229166865348816, 0.7816091775894165, 0.012820512987673283, 0.9541984796524048, 0.7654321193695068, 0.7888888716697693, 1.0, 0.841269850730896, 0.7472527623176575, 0.7572815418243408, 0.5833333134651184, 0.01315789483487606, 0.8217821717262268, 0.7586206793785095, 0.8558558821678162, 0.7945205569267273, 0.4000000059604645, 0.5, 0.012500000186264515, 0.8695651888847351, 0.8928571343421936, 0.013071895577013493, 1.0, 0.7254902124404907, 0.6893203854560852, 1.0, 0.8041236996650696, 1.0, 0.8661417365074158, 1.0, 0.8243243098258972, 0.8099173307418823, 0.9767441749572754, 1.0, 0.7868852615356445, 0.8272727131843567, 0.8692810535430908, 1.0, 0.013333333656191826, 1.0, 0.014492753893136978, 0.6516854166984558, 0.747474730014801, 0.834645688533783, 0.7964601516723633, 0.9509803652763367, 0.8214285969734192, 0.8559321761131287, 1.0]\n","simple_rank_outputs = [0.7244094610214233, 0.7324841022491455, 0.7415730357170105, 1.0, 0.7572815418243408, 0.8396946787834167, 1.0, 0.8600000143051147, 0.02500000037252903, 0.8235294222831726, 0.8380281925201416, 0.8064516186714172, 0.14499999582767487, 1.0, 0.8067227005958557, 0.8680555820465088, 0.8630136847496033, 0.8741258978843689, 0.7931034564971924, 0.013793103396892548, 0.7903226017951965, 1.0, 0.7627118825912476, 0.8960000276565552, 0.8481012582778931, 0.7594936490058899, 0.8387096524238586, 0.7222222089767456, 0.7299270033836365, 0.7848101258277893, 0.7898089289665222, 1.0, 0.8086956739425659, 0.03333333507180214, 1.0, 0.0714285746216774, 1.0, 0.7340425252914429, 0.8235294222831726, 0.875, 0.7721518874168396, 0.009999999776482582, 0.6853932738304138, 0.004999999888241291, 1.0, 0.8500000238418579, 1.0, 0.8782608509063721, 0.7606837749481201, 0.014999999664723873, 0.7735849022865295, 0.7916666865348816, 0.6551724076271057, 0.012820512987673283, 0.7633587718009949, 0.7777777910232544, 0.855555534362793, 1.0, 0.7777777910232544, 0.8241758346557617, 0.7961165308952332, 0.0833333358168602, 0.01315789483487606, 0.8712871074676514, 0.8390804529190063, 0.8198198080062866, 0.8630136847496033, 0.4000000059604645, 0.1666666716337204, 0.012500000186264515, 0.8695651888847351, 0.8095238208770752, 0.7843137383460999, 1.0, 0.7941176295280457, 0.708737850189209, 1.0, 0.6907216310501099, 1.0, 0.8897637724876404, 1.0, 0.837837815284729, 0.8181818127632141, 0.9224806427955627, 1.0, 0.8032786846160889, 0.800000011920929, 0.8039215803146362, 1.0, 0.8866666555404663, 1.0, 0.9637681245803833, 0.8202247023582458, 0.808080792427063, 0.9212598204612732, 0.8761062026023865, 0.7450980544090271, 0.7976190447807312, 0.8644067645072937, 1.0]\n","regression_outputs = [0.7952755689620972, 0.8152866363525391, 0.6966292262077332, 1.0, 0.7766990065574646, 0.847328245639801, 1.0, 0.9133333563804626, 0.02500000037252903, 0.656862735748291, 0.8239436745643616, 0.9112903475761414, 0.14499999582767487, 1.0, 0.9159663915634155, 0.013888888992369175, 0.7739726305007935, 0.0139860138297081, 0.9425287246704102, 0.013793103396892548, 0.9435483813285828, 1.0, 0.7627118825912476, 0.8799999952316284, 0.012658228166401386, 0.7784810066223145, 0.7311828136444092, 0.7129629850387573, 0.8321167826652527, 0.8860759735107422, 0.012738853693008423, 0.014492753893136978, 0.678260862827301, 0.03333333507180214, 1.0, 0.0714285746216774, 1.0, 0.7127659320831299, 0.843137264251709, 0.7890625, 0.8101266026496887, 0.009999999776482582, 0.7977527976036072, 0.004999999888241291, 0.01652892492711544, 0.7699999809265137, 1.0, 0.6695652008056641, 0.7606837749481201, 0.014999999664723873, 0.805031418800354, 0.84375, 0.931034505367279, 0.012820512987673283, 0.8549618124961853, 0.8765432238578796, 0.7222222089767456, 1.0, 0.8730158805847168, 0.6813187003135681, 1.0, 0.0833333358168602, 0.01315789483487606, 0.7623762488365173, 0.7701149582862854, 0.684684693813324, 0.8287671208381653, 0.20000000298023224, 0.1666666716337204, 0.012500000186264515, 0.739130437374115, 0.7857142686843872, 0.013071895577013493, 1.0, 0.7352941036224365, 0.6699029207229614, 1.0, 0.6391752362251282, 1.0, 0.8267716765403748, 1.0, 0.8716216087341309, 0.702479362487793, 0.8682170510292053, 1.0, 0.7950819730758667, 0.7454545497894287, 0.7516340017318726, 1.0, 0.800000011920929, 1.0, 0.014492753893136978, 0.7865168452262878, 0.6868686676025391, 0.7165354490280151, 0.6637167930603027, 0.8235294222831726, 0.8690476417541504, 0.6779661178588867, 1.0]\n","pairwise_rank_outputs = [0.7637795209884644, 0.7643312215805054, 0.7528089880943298, 1.0, 0.8834951519966125, 0.7557252049446106, 1.0, 0.013333333656191826, 1.0, 0.8235294222831726, 0.6971830725669861, 0.7983871102333069, 1.0, 1.0, 0.7815126180648804, 0.013888888992369175, 0.7397260069847107, 0.0139860138297081, 0.7701149582862854, 0.013793103396892548, 0.6693548560142517, 1.0, 0.8644067645072937, 0.7919999957084656, 0.012658228166401386, 0.6645569801330566, 0.774193525314331, 0.8333333134651184, 0.8029196858406067, 0.012658228166401386, 0.7579618096351624, 0.014492753893136978, 0.782608687877655, 0.2666666805744171, 1.0, 0.6428571343421936, 1.0, 0.7978723645210266, 0.7450980544090271, 0.78125, 0.753164529800415, 1.0, 0.7191011309623718, 1.0, 0.01652892492711544, 0.8500000238418579, 1.0, 0.7652173638343811, 0.7435897588729858, 1.0, 0.805031418800354, 0.84375, 0.7356321811676025, 0.012820512987673283, 0.7099236845970154, 0.8518518805503845, 0.7333333492279053, 1.0, 0.7698412537574768, 0.8461538553237915, 0.7766990065574646, 0.3333333432674408, 0.01315789483487606, 0.8613861203193665, 0.7931034564971924, 0.7207207083702087, 0.7602739930152893, 0.4000000059604645, 0.5, 0.012500000186264515, 0.7739130258560181, 0.8928571343421936, 0.758169949054718, 1.0, 0.8627451062202454, 0.8834951519966125, 1.0, 0.8556700944900513, 1.0, 0.6929134130477905, 1.0, 0.8040540814399719, 0.7933884263038635, 0.7054263353347778, 1.0, 0.7131147384643555, 0.7909091114997864, 0.013071895577013493, 1.0, 0.8199999928474426, 1.0, 0.014492753893136978, 0.6741573214530945, 0.868686854839325, 0.9055117964744568, 0.7876105904579163, 0.8921568393707275, 0.8095238208770752, 0.8389830589294434, 1.0]\n","pairwise_rank_instance_outputs = [0.7716535329818726, 0.7643312215805054, 0.8426966071128845, 1.0, 0.7766990065574646, 0.7557252049446106, 1.0, 0.9599999785423279, 1.0, 0.656862735748291, 0.8521126508712769, 0.725806474685669, 1.0, 1.0, 0.7815126180648804, 0.9166666865348816, 0.8082191944122314, 1.0, 0.7586206793785095, 0.013793103396892548, 0.6693548560142517, 1.0, 0.805084764957428, 0.8159999847412109, 0.012658228166401386, 0.8417721390724182, 0.8817204236984253, 0.8888888955116272, 0.8029196858406067, 0.012658228166401386, 0.8025477528572083, 0.014492753893136978, 0.7739130258560181, 0.2666666805744171, 1.0, 0.5714285969734192, 1.0, 0.7553191781044006, 0.7450980544090271, 0.890625, 0.8481012582778931, 1.0, 0.6966292262077332, 1.0, 0.01652892492711544, 0.8700000047683716, 1.0, 0.8782608509063721, 0.7606837749481201, 1.0, 0.805031418800354, 0.8020833134651184, 0.8390804529190063, 0.012820512987673283, 0.7404580116271973, 0.8518518805503845, 0.9555555582046509, 1.0, 0.738095223903656, 0.7692307829856873, 0.7572815418243408, 0.3333333432674408, 0.01315789483487606, 0.7029703259468079, 0.7701149582862854, 0.8558558821678162, 1.0, 0.6000000238418579, 0.5, 0.012500000186264515, 0.739130437374115, 0.988095223903656, 0.758169949054718, 1.0, 0.7843137383460999, 0.6699029207229614, 1.0, 0.8865979313850403, 1.0, 0.6929134130477905, 1.0, 0.7432432174682617, 0.702479362487793, 0.7054263353347778, 1.0, 0.7950819730758667, 0.7727272510528564, 0.8888888955116272, 1.0, 0.8199999928474426, 1.0, 0.9637681245803833, 0.6292135119438171, 0.6868686676025391, 0.834645688533783, 0.6637167930603027, 0.7450980544090271, 0.9642857313156128, 0.8305084705352783, 1.0]\n","regression_instance_outputs = [0.7795275449752808, 0.012738853693008423, 0.7865168452262878, 1.0, 0.8834951519966125, 0.8320610523223877, 1.0, 0.013333333656191826, 1.0, 0.8921568393707275, 1.0, 0.8145161271095276, 1.0, 1.0, 0.9495798349380493, 0.9166666865348816, 0.7534246444702148, 0.9510489702224731, 0.7471264600753784, 0.9379310607910156, 0.8387096524238586, 1.0, 0.7966101765632629, 0.8880000114440918, 0.9367088675498962, 0.7911392450332642, 1.0, 0.8148148059844971, 0.9416058659553528, 0.905063271522522, 0.012738853693008423, 1.0, 0.843478262424469, 0.3333333432674408, 1.0, 0.6428571343421936, 1.0, 0.8829787373542786, 0.7450980544090271, 0.9609375, 0.753164529800415, 1.0, 0.7528089880943298, 1.0, 1.0, 0.8999999761581421, 1.0, 0.895652174949646, 0.8461538553237915, 1.0, 0.805031418800354, 1.0, 0.6781609058380127, 1.0, 0.9160305261611938, 0.7407407164573669, 0.9444444179534912, 1.0, 0.9047619104385376, 0.9340659379959106, 0.7864077687263489, 0.3333333432674408, 0.01315789483487606, 0.7623762488365173, 0.8735632300376892, 0.7387387156486511, 0.8287671208381653, 0.4000000059604645, 0.5, 0.012500000186264515, 0.8695651888847351, 0.7976190447807312, 0.9411764740943909, 1.0, 0.8529411554336548, 0.708737850189209, 1.0, 0.7835051417350769, 1.0, 0.8503937125205994, 1.0, 0.8243243098258972, 0.93388432264328, 0.8914728760719299, 1.0, 0.9180327653884888, 0.8272727131843567, 0.8888888955116272, 1.0, 0.8866666555404663, 1.0, 0.9637681245803833, 0.8426966071128845, 0.7979797720909119, 0.9055117964744568, 0.9469026327133179, 0.8039215803146362, 0.7976190447807312, 0.7711864113807678, 1.0]"],"metadata":{"id":"ErZhkccP6mga","executionInfo":{"status":"ok","timestamp":1703028243615,"user_tz":480,"elapsed":5,"user":{"displayName":"Jia He Sun","userId":"07783893916712904513"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import numpy as np\n","\n","bins = np.linspace(0, 1, 11)\n","\n","# Calculate histograms\n","hist_bc, _ = np.histogram(bc_outputs, bins=bins)\n","hist_simple_rank, _ = np.histogram(simple_rank_outputs, bins=bins)\n","hist_pairwise_rank, _ = np.histogram(pairwise_rank_outputs, bins=bins)\n","hist_regression, _ = np.histogram(regression_outputs, bins=bins)\n","hist_regression_instance, _ = np.histogram(regression_instance_outputs, bins=bins)\n","\n","# Calculate bin centers\n","bin_centers = (bins[:-1] + bins[1:]) / 2\n","\n","# Plot line graphs\n","plt.plot(bin_centers, hist_bc, label='Binary Classification')\n","plt.plot(bin_centers, hist_simple_rank, label='SimpleRank')\n","plt.plot(bin_centers, hist_pairwise_rank, label='PairwiseRank')\n","plt.plot(bin_centers, hist_regression, label='Regression')\n","plt.plot(bin_centers, hist_regression_instance, label='Regression Instance')\n","\n","# Extend x-axis to include 1\n","plt.xlim(0, 1)\n","\n","# Add labels and title\n","plt.xlabel('Actual Expert Policy Labels of Selected Nodes')\n","plt.ylabel('Frequency (Percentage)')\n","plt.title('Performance Distribution of Imitation Learning Models')\n","\n","# Add legend\n","plt.legend()\n","\n","# Show the plot\n","plt.show()\n"],"metadata":{"id":"zDUq0oQW6wep"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"tS3-hKUyZHku"},"execution_count":null,"outputs":[]}]}